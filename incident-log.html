<!doctype html>
<html lang="en" class="govuk-template no-js">
  <head>
    <meta content="IE=edge" http-equiv="X-UA-Compatible">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, viewport-fit=cover">

    <title>Incident Log - Cloud Platform Runbooks</title>

    <link href="/stylesheets/manifest.css" rel="stylesheet" />

    <link rel="canonical" href="https://runbooks.cloud-platform.service.justice.gov.uk/incident-log.html">

      <meta name="robots" content="noindex" />
      <meta name="twitter:card" content="summary" />
      <meta name="twitter:domain" content="runbooks.cloud-platform.service.justice.gov.uk" />
      <meta name="twitter:image" content="https://runbooks.cloud-platform.service.justice.gov.uk/images/govuk-large.png" />
      <meta name="twitter:title" content="Incident Log - Cloud Platform Runbooks" />
      <meta name="twitter:url" content="https://runbooks.cloud-platform.service.justice.gov.uk/incident-log.html" />

      <meta property="og:image" content="https://runbooks.cloud-platform.service.justice.gov.uk/images/govuk-large.png" />
      <meta property="og:site_name" content="Cloud Platform Runbooks" />
      <meta property="og:title" content="Incident Log" />
      <meta property="og:type" content="object" />
      <meta property="og:url" content="https://runbooks.cloud-platform.service.justice.gov.uk/incident-log.html" />

    
  </head>

  <body class="govuk-template__body">
    <script>document.body.className = ((document.body.className) ? document.body.className + ' js-enabled' : 'js-enabled');</script>

    <div class="app-pane">
      <div class="app-pane__header toc-open-disabled">
        <a href="#content" class="govuk-skip-link">Skip to main content</a>

        <header class="govuk-header app-header" role="banner" data-module="govuk-header">
  <div class="govuk-header__container govuk-header__container--full-width">
    <div class="govuk-header__logo">
      <a href="/" class="govuk-header__link govuk-header__link--homepage">
        <span class="govuk-header__product-name">
          Cloud Platform Runbooks
        </span>
      </a>
    </div>
    <div class="govuk-header__content">
      <button type="button" class="govuk-header__menu-button govuk-js-header-toggle" aria-controls="navigation" aria-label="Show or hide Top Level Navigation">Menu</button>
      <nav>
        <ul id="navigation" class="govuk-header__navigation govuk-header__navigation--end" aria-label="Top Level Navigation">
            <li class="govuk-header__navigation-item">
              <a class="govuk-header__link" href="mailto:platforms+runbooks@digital.justice.gov.uk?subject=Runbooks+feedback">Feedback / Report a problem</a>
            </li>
            <li class="govuk-header__navigation-item">
              <a class="govuk-header__link" href="/">Documentation</a>
            </li>
            <li class="govuk-header__navigation-item">
              <a class="govuk-header__link" href="https://github.com/ministryofjustice/cloud-platform/tree/main/runbooks">GitHub</a>
            </li>
        </ul>
      </nav>
    </div>
  </div>
</header>

      </div>

        <div id="toc-heading" class="toc-show fixedsticky">
          <button type="button" class="toc-show__label js-toc-show" aria-controls="toc">
            Table of contents <span class="toc-show__icon"></span>
          </button>
        </div>

      <div class="app-pane__body" data-module="in-page-navigation">
          <div class="app-pane__toc">
            <div class="toc" data-module="table-of-contents" tabindex="-1" aria-label="Table of contents" role="dialog">
              <div class="search" data-module="search">
  <form action="https://www.google.co.uk/search" method="get" role="search" class="search__form govuk-!-margin-bottom-4">
    <input type="hidden" name="as_sitesearch" value="https://runbooks.cloud-platform.service.justice.gov.uk"/>
    <label class="govuk-label search__label" for="search" aria-hidden="true">
      Search (via Google)
    </label>
    <input
      type="text"
      id="search" name="q"
      class="govuk-input govuk-!-margin-bottom-0 search__input"
      aria-controls="search-results"
      placeholder="Search">
    <button type="submit" class="search__button">Search</button>
  </form>
  <div id="search-results" class="search-results" aria-hidden="true" role="dialog" aria-labelledby="search-results-title">
    <div class="search-results__inner">
      <button class="search-results__close">Close<span class="search-results__close-label"> search results</span></button>
      <h2 id="search-results-title" class="search-results__title" aria-live="assertive" role="alert">Results</h2>
      <div class="search-results__content"></div>
    </div>
  </div>
</div>

              <button type="button" class="toc__close js-toc-close" aria-controls="toc" aria-label="Hide table of contents"></button>
              <nav id="toc" class="js-toc-list toc__list" aria-labelledby="toc-heading" data-module="collapsible-navigation">
                      <ul>
  <li>
    <a href="/#cloud-platform-runbooks"><span>Cloud Platform Runbooks</span></a>
  </li>
</ul>
<ul>
  <li>
    <a href="/how-we-work.html#how-we-work"><span>How We Work</span></a>
    <ul>
      <li>
        <a href="/how-we-work.html#getting-help"><span>Getting Help</span></a>
      </li>
      <li>
        <a href="/how-we-work.html#the-board-tickets"><span>The Board / Tickets</span></a>
        <ul>
          <li>
            <a href="/how-we-work.html#adding-tickets"><span>Adding tickets</span></a>
          </li>
          <li>
            <a href="/how-we-work.html#making-changes-to-code"><span>Making changes to code</span></a>
          </li>
          <li>
            <a href="/how-we-work.html#reviewing-merging-prs"><span>Reviewing/Merging PRs</span></a>
          </li>
        </ul>
      </li>
      <li>
        <a href="/how-we-work.html#the-hammer-of-justice"><span>The üî® Hammer of Justice</span></a>
        <ul>
          <li>
            <a href="/how-we-work.html#backlog-tickets"><span>Backlog Tickets</span></a>
          </li>
        </ul>
      </li>
      <li>
        <a href="/how-we-work.html#documentation"><span>Documentation</span></a>
      </li>
    </ul>
  </li>
</ul>
<ul>
  <li>
    <a href="/incident-process.html#incident-process"><span>Incident Process</span></a>
    <ul>
      <li>
        <a href="/incident-process.html#1-confirm-that-the-event-constitutes-an-incident"><span>1. Confirm that the event constitutes an incident</span></a>
      </li>
      <li>
        <a href="/incident-process.html#2-declare-the-incident"><span>2. Declare the incident</span></a>
        <ul>
          <li>
            <a href="/incident-process.html#examples"><span>Examples</span></a>
          </li>
        </ul>
      </li>
      <li>
        <a href="/incident-process.html#3-assign-roles"><span>3. Assign roles</span></a>
        <ul>
          <li>
            <a href="/incident-process.html#3-1-incident-lead"><span>3.1 Incident Lead</span></a>
          </li>
          <li>
            <a href="/incident-process.html#3-2-scribe"><span>3.2 Scribe</span></a>
          </li>
          <li>
            <a href="/incident-process.html#3-3-communications-lead"><span>3.3 Communications Lead</span></a>
          </li>
          <li>
            <a href="/incident-process.html#transferring-roles"><span>Transferring roles</span></a>
          </li>
        </ul>
      </li>
      <li>
        <a href="/incident-process.html#4-fix-the-problem"><span>4. Fix the problem</span></a>
      </li>
      <li>
        <a href="/incident-process.html#5-end-the-incident"><span>5. End the incident</span></a>
      </li>
      <li>
        <a href="/incident-process.html#6-post-incident-procedure"><span>6. Post-incident procedure</span></a>
      </li>
    </ul>
  </li>
</ul>
<ul>
  <li>
    <a href="/incident-log.html#incident-log"><span>Incident Log</span></a>
    <ul>
      <li>
        <a href="/incident-log.html#q2-2021-apr-may"><span>Q2 2021 (Apr-May)</span></a>
        <ul>
          <li>
            <a href="/incident-log.html#incident-on-2021-07-12-15-24-all-ingress-resources-using-apps-live-1-domain-names-stop-working"><span>Incident on 2021-07-12 15:24 - All ingress resources using *apps.live-1 domain names stop working</span></a>
          </li>
          <li>
            <a href="/incident-log.html#incident-on-2021-06-09-12-47-all-users-are-unable-to-create-new-ingress-rules-following-bad-modsec-ingress-controller-upgrade"><span>Incident on 2021-06-09 12:47 - All users are unable to create new ingress rules, following bad ModSec Ingress-controller upgrade</span></a>
          </li>
          <li>
            <a href="/incident-log.html#incident-on-2021-05-10-12-15-apply-pipeline-downtime-due-to-accidental-destroy-of-manager-cluster"><span>Incident on 2021-05-10 12:15 - Apply Pipeline downtime due to accidental destroy of Manager cluster</span></a>
          </li>
        </ul>
      </li>
      <li>
        <a href="/incident-log.html#q1-2021-january-march"><span>Q1 2021 (January - March)</span></a>
        <ul>
          <li>
            <a href="/incident-log.html#no-incidents-declared"><span>No incidents declared</span></a>
          </li>
        </ul>
      </li>
      <li>
        <a href="/incident-log.html#q4-2020-october-december"><span>Q4 2020 (October - December)</span></a>
        <ul>
          <li>
            <a href="/incident-log.html#incident-on-2020-10-06-09-07-intermittent-quot-micro-downtimes-quot-on-various-services-using-dedicated-ingress-controllers"><span>Incident on 2020-10-06 09:07 - Intermittent ‚Äúmicro-downtimes‚Äù on various services using dedicated ingress controllers</span></a>
          </li>
        </ul>
      </li>
      <li>
        <a href="/incident-log.html#q3-2020-july-september"><span>Q3 2020 (July - September)</span></a>
        <ul>
          <li>
            <a href="/incident-log.html#incident-on-2020-09-28-13-10-termination-of-nodes-updating-kops-instance-group"><span>Incident on 2020-09-28 13:10 - Termination of nodes updating kops Instance Group.</span></a>
          </li>
          <li>
            <a href="/incident-log.html#incident-on-2020-09-21-18-27-some-cloud-platform-components-destroyed"><span>Incident on 2020-09-21 18:27 - Some cloud-platform components destroyed.</span></a>
          </li>
          <li>
            <a href="/incident-log.html#incident-on-2020-09-07-12-54-all-users-are-unable-to-create-new-ingress-rules"><span>Incident on 2020-09-07 12:54 - All users are unable to create new ingress rules</span></a>
          </li>
          <li>
            <a href="/incident-log.html#incident-on-2020-08-25-11-26-connectivity-issues-with-eu-west-2a"><span>Incident on 2020-08-25 11:26 - Connectivity issues with eu-west-2a</span></a>
          </li>
          <li>
            <a href="/incident-log.html#incident-on-2020-08-14-11-01-ingress-controllers-crashlooping"><span>Incident on 2020-08-14 11:01 - Ingress-controllers crashlooping</span></a>
          </li>
          <li>
            <a href="/incident-log.html#incident-on-2020-08-07-16-39-master-node-provisioning-failure"><span>Incident on 2020-08-07 16:39 - Master node provisioning failure</span></a>
          </li>
        </ul>
      </li>
      <li>
        <a href="/incident-log.html#q2-2020-april-june"><span>Q2 2020 (April - June)</span></a>
        <ul>
          <li>
            <a href="/incident-log.html#incident-on-2020-08-04-17-13"><span>Incident on 2020-08-04 17:13</span></a>
          </li>
          <li>
            <a href="/incident-log.html#incident-on-2020-04-15-10-58-nginx-tls"><span>Incident on 2020-04-15 10:58 Nginx/TLS</span></a>
          </li>
        </ul>
      </li>
      <li>
        <a href="/incident-log.html#q1-2020-january-march"><span>Q1 2020 (January - March)</span></a>
        <ul>
          <li>
            <a href="/incident-log.html#incident-on-2020-02-25-10-58"><span>Incident on 2020-02-25 10:58</span></a>
          </li>
          <li>
            <a href="/incident-log.html#incident-on-2020-02-18-14-13-utc"><span>Incident on 2020-02-18 14:13 UTC</span></a>
          </li>
          <li>
            <a href="/incident-log.html#incident-on-2020-02-12-11-45-utc"><span>Incident on 2020-02-12 11:45 UTC</span></a>
          </li>
        </ul>
      </li>
      <li>
        <a href="/incident-log.html#about-this-incident-log"><span>About this incident log</span></a>
      </li>
      <li>
        <a href="/incident-log.html#template"><span>Template</span></a>
        <ul>
          <li>
            <a href="/incident-log.html#incident-on-yyyy-mm-dd-hh-mm-brief-description"><span>Incident on YYYY-MM-DD HH:MM - [Brief description]</span></a>
          </li>
        </ul>
      </li>
      <li>
        <a href="/incident-log.html#impact"><span>Impact:</span></a>
      </li>
      <li>
        <a href="/incident-log.html#context"><span>Context:</span></a>
      </li>
      <li>
        <a href="/incident-log.html#resolution"><span>Resolution:</span></a>
      </li>
    </ul>
  </li>
</ul>
<ul>
  <li>
    <a href="/create-cluster.html#create-a-new-cluster"><span>Create a new cluster</span></a>
    <ul>
      <li>
        <a href="/create-cluster.html#pre-requisites"><span>Pre-requisites</span></a>
      </li>
      <li>
        <a href="/create-cluster.html#environment-variables"><span>Environment Variables</span></a>
      </li>
      <li>
        <a href="/create-cluster.html#run-the-build-script-via-the-tools-image"><span>Run the build script, via the tools image</span></a>
      </li>
      <li>
        <a href="/create-cluster.html#alerts"><span>Alerts</span></a>
        <ul>
          <li>
            <a href="/create-cluster.html#apply-the-changes"><span>Apply the changes</span></a>
          </li>
        </ul>
      </li>
      <li>
        <a href="/create-cluster.html#authenticating"><span>Authenticating</span></a>
      </li>
      <li>
        <a href="/create-cluster.html#docker-authentication"><span>Docker authentication</span></a>
        <ul>
          <li>
            <a href="/create-cluster.html#adding-a-docker-config-file-to-your-cluster"><span>Adding a Docker config file to your cluster</span></a>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>
<ul>
  <li>
    <a href="/changes-in-cloudplatform.html#change-process-in-cloud-platform"><span>Change Process in Cloud Platform</span></a>
    <ul>
      <li>
        <a href="/changes-in-cloudplatform.html#making-changes-to-cloud-plarform-infrastructure"><span>Making Changes to cloud-plarform-infrastructure</span></a>
      </li>
      <li>
        <a href="/changes-in-cloudplatform.html#marking-changes-to-terraform-modules"><span>Marking Changes to terraform modules</span></a>
      </li>
      <li>
        <a href="/changes-in-cloudplatform.html#making-changes-to-helm-charts"><span>Making Changes to Helm Charts</span></a>
      </li>
      <li>
        <a href="/changes-in-cloudplatform.html#making-changes-to-environments-service-teams"><span>Making changes to environments (Service Teams)</span></a>
      </li>
      <li>
        <a href="/changes-in-cloudplatform.html#communications"><span>Communications</span></a>
      </li>
    </ul>
  </li>
</ul>
<ul>
  <li>
    <a href="/add-concourse-to-cluster.html#add-concourse-to-a-test-cluster"><span>Add Concourse to a test cluster</span></a>
    <ul>
      <li>
        <a href="/add-concourse-to-cluster.html#add-concourse-to-a-test-cluster-pre-requisites"><span>Pre-requisites</span></a>
      </li>
      <li>
        <a href="/add-concourse-to-cluster.html#process"><span>Process</span></a>
      </li>
    </ul>
  </li>
</ul>
<ul>
  <li>
    <a href="/upgrade-cluster.html#upgrade-a-cluster"><span>Upgrade a cluster</span></a>
    <ul>
      <li>
        <a href="/upgrade-cluster.html#planning"><span>Planning</span></a>
      </li>
      <li>
        <a href="/upgrade-cluster.html#upgrade-a-cluster-pre-requisites"><span>Pre-requisites</span></a>
        <ul>
          <li>
            <a href="/upgrade-cluster.html#setup-environment"><span>Setup environment</span></a>
          </li>
          <li>
            <a href="/upgrade-cluster.html#run-the-integration-tests"><span>Run the integration tests</span></a>
          </li>
          <li>
            <a href="/upgrade-cluster.html#sanity-checks"><span>Sanity checks</span></a>
          </li>
          <li>
            <a href="/upgrade-cluster.html#run-a-shell-in-the-tools-image"><span>Run a shell in the tools image</span></a>
          </li>
        </ul>
      </li>
      <li>
        <a href="/upgrade-cluster.html#run-the-upgrade"><span>Run the upgrade</span></a>
        <ul>
          <li>
            <a href="/upgrade-cluster.html#authenticate-to-the-cluster"><span>Authenticate to the cluster</span></a>
          </li>
          <li>
            <a href="/upgrade-cluster.html#update-the-live-cluster-manifest"><span>Update the live cluster manifest</span></a>
          </li>
          <li>
            <a href="/upgrade-cluster.html#push-changes-to-kops-state"><span>Push changes to kops state</span></a>
          </li>
          <li>
            <a href="/upgrade-cluster.html#perform-a-rolling-update"><span>Perform a rolling-update</span></a>
          </li>
          <li>
            <a href="/upgrade-cluster.html#take-stock-of-current-running-worker-nodes"><span>Take stock of current running worker nodes</span></a>
          </li>
          <li>
            <a href="/upgrade-cluster.html#create-new-worker-instance-groups"><span>Create new worker instance groups</span></a>
          </li>
          <li>
            <a href="/upgrade-cluster.html#cordon-old-workers"><span>Cordon old workers</span></a>
          </li>
          <li>
            <a href="/upgrade-cluster.html#scale-the-number-of-ingress-controllers"><span>Scale the number of ingress controllers</span></a>
          </li>
          <li>
            <a href="/upgrade-cluster.html#drain-the-old-worker-nodes"><span>Drain the old worker nodes</span></a>
          </li>
          <li>
            <a href="/upgrade-cluster.html#validate-the-cluster"><span>Validate the cluster</span></a>
          </li>
          <li>
            <a href="/upgrade-cluster.html#run-the-integration-tests-again"><span>Run the integration tests again</span></a>
          </li>
          <li>
            <a href="/upgrade-cluster.html#delete-the-old-instance-groups"><span>Delete the old instance groups</span></a>
          </li>
          <li>
            <a href="/upgrade-cluster.html#scale-the-ingress-controllers-down"><span>Scale the ingress-controllers down</span></a>
          </li>
        </ul>
      </li>
      <li>
        <a href="/upgrade-cluster.html#commit-changes-back-to-main-branch"><span>Commit changes back to main branch</span></a>
      </li>
    </ul>
  </li>
</ul>
<ul>
  <li>
    <a href="/upgrade-eks-cluster.html#upgrade-eks-cluster-s"><span>Upgrade EKS cluster(s)</span></a>
    <ul>
      <li>
        <a href="/upgrade-eks-cluster.html#upgrade-eks-cluster-s-pre-requisites"><span>Pre-requisites</span></a>
      </li>
      <li>
        <a href="/upgrade-eks-cluster.html#upgrade-eks-cluster-s-run-the-upgrade"><span>Run the upgrade</span></a>
        <ul>
          <li>
            <a href="/upgrade-eks-cluster.html#upgrade-control-plane"><span>Upgrade Control Plane</span></a>
          </li>
          <li>
            <a href="/upgrade-eks-cluster.html#upgrade-node-groups"><span>Upgrade Node Groups</span></a>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>
<ul>
  <li>
    <a href="/upgrade-terraform-version.html#upgrade-terraform-version"><span>Upgrade Terraform Version</span></a>
    <ul>
      <li>
        <a href="/upgrade-terraform-version.html#introduction"><span>Introduction</span></a>
      </li>
      <li>
        <a href="/upgrade-terraform-version.html#recommendations"><span>Recommendations</span></a>
      </li>
      <li>
        <a href="/upgrade-terraform-version.html#caveats"><span>Caveats</span></a>
      </li>
      <li>
        <a href="/upgrade-terraform-version.html#how-to-perform-the-upgrade-divide-and-conquer"><span>How to perform the upgrade - divide and conquer</span></a>
        <ul>
          <li>
            <a href="/upgrade-terraform-version.html#before-the-upgrade"><span>Before the upgrade</span></a>
          </li>
          <li>
            <a href="/upgrade-terraform-version.html#environments-state-files"><span>Environments state files</span></a>
          </li>
          <li>
            <a href="/upgrade-terraform-version.html#infrastructure-state-files"><span>Infrastructure state files</span></a>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>
<ul>
  <li>
    <a href="/upgrade-cluster-components.html#upgrade-cluster-components"><span>Upgrade cluster components</span></a>
    <ul>
      <li>
        <a href="/upgrade-cluster-components.html#upgrade-cluster-components-planning"><span>Planning</span></a>
      </li>
      <li>
        <a href="/upgrade-cluster-components.html#testing-the-upgrade-in-a-test-cluster"><span>Testing the upgrade in a test cluster</span></a>
        <ul>
          <li>
            <a href="/upgrade-cluster-components.html#testing-the-upgrade-in-a-test-cluster-setup-environment"><span>Setup environment</span></a>
          </li>
          <li>
            <a href="/upgrade-cluster-components.html#testing-the-upgrade-in-a-test-cluster-run-a-shell-in-the-tools-image"><span>Run a shell in the tools image</span></a>
          </li>
          <li>
            <a href="/upgrade-cluster-components.html#authenticate-to-the-test-cluster"><span>Authenticate to the test cluster</span></a>
          </li>
          <li>
            <a href="/upgrade-cluster-components.html#testing-the-upgrade-in-a-test-cluster-run-the-integration-tests"><span>Run the integration tests</span></a>
          </li>
          <li>
            <a href="/upgrade-cluster-components.html#testing-the-upgrade"><span>Testing the upgrade</span></a>
          </li>
          <li>
            <a href="/upgrade-cluster-components.html#things-to-observe-when-testing-the-upgrade"><span>Things to observe when testing the upgrade</span></a>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>
<ul>
  <li>
    <a href="/delete-cluster.html#delete-a-cluster"><span>Delete a cluster</span></a>
    <ul>
      <li>
        <a href="/delete-cluster.html#delete-the-cluster-using-the-script"><span>Delete the cluster using the script</span></a>
        <ul>
          <li>
            <a href="/delete-cluster.html#first-run-make-tools-shell"><span>First, run make tools-shell</span></a>
          </li>
        </ul>
      </li>
      <li>
        <a href="/delete-cluster.html#delete-the-cluster-using-concourse-fly-commands"><span>Delete the cluster using concourse fly commands</span></a>
      </li>
      <li>
        <a href="/delete-cluster.html#delete-the-cluster-manually"><span>Delete the cluster manually</span></a>
      </li>
      <li>
        <a href="/delete-cluster.html#delete-an-eks-cluster"><span>Delete an EKS cluster</span></a>
      </li>
    </ul>
  </li>
</ul>
<ul>
  <li>
    <a href="/add-nodes-to-the-cluster.html#add-nodes-to-the-cluster"><span>Add nodes to the cluster</span></a>
    <ul>
      <li>
        <ul>
          <li>
            <a href="/add-nodes-to-the-cluster.html#requirements"><span>Requirements</span></a>
          </li>
          <li>
            <a href="/add-nodes-to-the-cluster.html#inline-edit"><span>Inline edit</span></a>
          </li>
          <li>
            <a href="/add-nodes-to-the-cluster.html#persisting-the-changes"><span>Persisting the changes</span></a>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>
<ul>
  <li>
    <a href="/add-nodes-to-the-eks-cluster.html#add-nodes-change-the-instance-type-of-the-aws-eks-cluster"><span>Add nodes/change the instance type of the AWS EKS cluster</span></a>
    <ul>
      <li>
        <a href="/add-nodes-to-the-eks-cluster.html#add-nodes-to-the-eks-cluster"><span>Add nodes to the eks cluster</span></a>
        <ul>
          <li>
            <a href="/add-nodes-to-the-eks-cluster.html#add-nodes-to-the-eks-cluster-requirements"><span>Requirements</span></a>
          </li>
          <li>
            <a href="/add-nodes-to-the-eks-cluster.html#cluster-configuration"><span>Cluster configuration:</span></a>
          </li>
          <li>
            <a href="/add-nodes-to-the-eks-cluster.html#issue"><span>Issue</span></a>
          </li>
        </ul>
      </li>
      <li>
        <a href="/add-nodes-to-the-eks-cluster.html#change-the-aws-eks-instance-type-worker-node-machine-type"><span>Change the AWS EKS instance type (worker_node_machine_type)</span></a>
      </li>
    </ul>
  </li>
</ul>
<ul>
  <li>
    <a href="/auth0-rotation.html#credentials-rotation-for-auth0-apps"><span>Credentials rotation for auth0 apps</span></a>
    <ul>
      <li>
        <a href="/auth0-rotation.html#preparation"><span>Preparation</span></a>
      </li>
      <li>
        <a href="/auth0-rotation.html#1-taint-resources-terraform"><span>1) Taint resources (terraform)</span></a>
      </li>
      <li>
        <a href="/auth0-rotation.html#2-rolling-update-of-cluster-kops"><span>2) Rolling update of cluster (kops)</span></a>
      </li>
      <li>
        <a href="/auth0-rotation.html#3-apply-changes-within-components-terraform"><span>3) Apply changes within components (terraform)</span></a>
      </li>
      <li>
        <a href="/auth0-rotation.html#4-update-environment-repo"><span>4) Update environment repo</span></a>
      </li>
      <li>
        <a href="/auth0-rotation.html#5-verifiying-changes"><span>5) Verifiying changes</span></a>
      </li>
      <li>
        <a href="/auth0-rotation.html#6-update-pipelines"><span>6) Update pipelines</span></a>
      </li>
    </ul>
  </li>
</ul>
<ul>
  <li>
    <a href="/rotate-git-crypt-key.html#git-crypt"><span>Git-crypt</span></a>
    <ul>
      <li>
        <a href="/rotate-git-crypt-key.html#adding-new-user-to-the-keyring"><span>Adding new user to the keyring</span></a>
      </li>
      <li>
        <a href="/rotate-git-crypt-key.html#rotating-the-git-crypt-key"><span>Rotating the git-crypt key</span></a>
        <ul>
          <li>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>
<ul>
  <li>
    <a href="/custom-domain.html#add-a-custom-domain"><span>Add a custom domain</span></a>
  </li>
</ul>
<ul>
  <li>
    <a href="/add-new-receiver-alert-manager.html#add-a-new-alertmanager-receiver-and-a-slack-webhook"><span>Add a new Alertmanager receiver and a slack webhook</span></a>
    <ul>
      <li>
        <a href="/add-new-receiver-alert-manager.html#add-a-new-alertmanager-receiver-and-a-slack-webhook-pre-requisites"><span>Pre-requisites</span></a>
      </li>
      <li>
        <a href="/add-new-receiver-alert-manager.html#creating-a-new-receiver-set"><span>Creating a new receiver set</span></a>
      </li>
      <li>
        <a href="/add-new-receiver-alert-manager.html#information-alerts"><span>Information Alerts</span></a>
      </li>
    </ul>
  </li>
</ul>
<ul>
  <li>
    <a href="/disaster-recovery.html#cloud-platform-disaster-recovery"><span>Cloud Platform Disaster Recovery</span></a>
    <ul>
      <li>
        <a href="/disaster-recovery.html#restore-process"><span>Restore process</span></a>
      </li>
      <li>
        <a href="/disaster-recovery.html#apply-cloud-platform-resources"><span>Apply cloud-platform resources</span></a>
      </li>
      <li>
        <a href="/disaster-recovery.html#cloud-platform-disaster-recovery-create-a-new-cluster"><span>Create a new cluster</span></a>
      </li>
      <li>
        <a href="/disaster-recovery.html#perform-the-restore"><span>Perform the restore</span></a>
        <ul>
          <li>
            <a href="/disaster-recovery.html#perform-the-restore-pre-requisites"><span>Pre-requisites</span></a>
          </li>
          <li>
            <a href="/disaster-recovery.html#restore-the-cluster-using-etcd-manager-ctl-on-your-computer"><span>Restore the cluster using etcd-manager-ctl on your computer.</span></a>
          </li>
          <li>
            <a href="/disaster-recovery.html#restore-process-inside-the-etcd-container-using-etcd-manager-ctl"><span>Restore process inside the etcd container using etcd-manager-ctl.</span></a>
          </li>
        </ul>
      </li>
      <li>
        <a href="/disaster-recovery.html#cleanup"><span>Cleanup</span></a>
      </li>
      <li>
        <a href="/disaster-recovery.html#possible-issues"><span>Possible Issues</span></a>
      </li>
    </ul>
  </li>
</ul>
<ul>
  <li>
    <a href="/disaster-recovery-scenarios.html#cloud-platform-disaster-recovery-scenarios"><span>Cloud Platform Disaster Recovery Scenarios</span></a>
    <ul>
      <li>
        <a href="/disaster-recovery-scenarios.html#losing-a-namespace"><span>Losing a Namespace</span></a>
        <ul>
          <li>
            <a href="/disaster-recovery-scenarios.html#losing-a-namespace-impact"><span>Impact</span></a>
          </li>
          <li>
            <a href="/disaster-recovery-scenarios.html#possible-cause"><span>Possible Cause</span></a>
          </li>
          <li>
            <a href="/disaster-recovery-scenarios.html#losing-a-namespace-restore-process"><span>Restore process</span></a>
          </li>
        </ul>
      </li>
      <li>
        <a href="/disaster-recovery-scenarios.html#losing-a-kubernetes-component-or-object"><span>Losing a Kubernetes Component or Object</span></a>
        <ul>
          <li>
            <a href="/disaster-recovery-scenarios.html#losing-a-kubernetes-component-or-object-impact"><span>Impact</span></a>
          </li>
          <li>
            <a href="/disaster-recovery-scenarios.html#losing-a-kubernetes-component-or-object-possible-cause"><span>Possible Cause</span></a>
          </li>
          <li>
            <a href="/disaster-recovery-scenarios.html#losing-a-kubernetes-component-or-object-restore-process"><span>Restore process</span></a>
          </li>
        </ul>
      </li>
      <li>
        <a href="/disaster-recovery-scenarios.html#losing-the-whole-cluster"><span>Losing the whole cluster</span></a>
        <ul>
          <li>
            <a href="/disaster-recovery-scenarios.html#losing-the-whole-cluster-impact"><span>Impact</span></a>
          </li>
          <li>
            <a href="/disaster-recovery-scenarios.html#losing-the-whole-cluster-possible-cause"><span>Possible Cause</span></a>
          </li>
          <li>
            <a href="/disaster-recovery-scenarios.html#how-this-plan-is-tested"><span>How this plan is tested:</span></a>
          </li>
          <li>
            <a href="/disaster-recovery-scenarios.html#assumptions"><span>Assumptions</span></a>
          </li>
          <li>
            <a href="/disaster-recovery-scenarios.html#losing-the-whole-cluster-restore-process"><span>Restore process</span></a>
          </li>
        </ul>
      </li>
      <li>
        <a href="/disaster-recovery-scenarios.html#deleted-corrupted-the-kops-state"><span>Deleted/corrupted the kops state</span></a>
        <ul>
          <li>
            <a href="/disaster-recovery-scenarios.html#deleted-corrupted-the-kops-state-impact"><span>Impact</span></a>
          </li>
          <li>
            <a href="/disaster-recovery-scenarios.html#deleted-corrupted-the-kops-state-possible-cause"><span>Possible Cause</span></a>
          </li>
          <li>
            <a href="/disaster-recovery-scenarios.html#restore-process-for-corrupted-kops-state"><span>Restore process for corrupted kops state</span></a>
          </li>
          <li>
            <a href="/disaster-recovery-scenarios.html#restore-process-for-deleted-s3-bucket-where-kops-state-is-stored"><span>Restore process for deleted S3 bucket where kops state is stored</span></a>
          </li>
        </ul>
      </li>
      <li>
        <a href="/disaster-recovery-scenarios.html#deleted-terraform-state"><span>Deleted terraform state</span></a>
        <ul>
          <li>
            <a href="/disaster-recovery-scenarios.html#deleted-terraform-state-impact"><span>Impact</span></a>
          </li>
          <li>
            <a href="/disaster-recovery-scenarios.html#deleted-terraform-state-possible-cause"><span>Possible Cause</span></a>
          </li>
          <li>
            <a href="/disaster-recovery-scenarios.html#deleted-terraform-state-restore-process"><span>Restore process</span></a>
          </li>
          <li>
            <a href="/disaster-recovery-scenarios.html#recovering-more-complex-scenarios"><span>Recovering more complex scenarios</span></a>
          </li>
        </ul>
      </li>
      <li>
        <a href="/disaster-recovery-scenarios.html#lost-or-corrupt-etcd-volume"><span>Lost or corrupt etcd volume</span></a>
        <ul>
          <li>
            <a href="/disaster-recovery-scenarios.html#lost-or-corrupt-etcd-volume-impact"><span>Impact</span></a>
          </li>
          <li>
            <a href="/disaster-recovery-scenarios.html#lost-or-corrupt-etcd-volume-possible-cause"><span>Possible Cause</span></a>
          </li>
          <li>
            <a href="/disaster-recovery-scenarios.html#lost-or-corrupt-etcd-volume-restore-process"><span>Restore process</span></a>
          </li>
        </ul>
      </li>
      <li>
        <a href="/disaster-recovery-scenarios.html#overwriting-kops-cluster-39-s-components-with-eks-components"><span>Overwriting KOPS cluster‚Äôs components with EKS components</span></a>
        <ul>
          <li>
            <a href="/disaster-recovery-scenarios.html#overwriting-kops-cluster-39-s-components-with-eks-components-impact"><span>Impact</span></a>
          </li>
          <li>
            <a href="/disaster-recovery-scenarios.html#overwriting-kops-cluster-39-s-components-with-eks-components-possible-cause"><span>Possible Cause</span></a>
          </li>
          <li>
            <a href="/disaster-recovery-scenarios.html#overwriting-kops-cluster-39-s-components-with-eks-components-restore-process"><span>Restore process</span></a>
          </li>
          <li>
            <a href="/disaster-recovery-scenarios.html#reproducing-incident-steps"><span>Reproducing Incident Steps</span></a>
          </li>
          <li>
            <a href="/disaster-recovery-scenarios.html#velero-backup"><span>Velero Backup</span></a>
          </li>
          <li>
            <a href="/disaster-recovery-scenarios.html#apply-the-eks-components-to-the-kops-cluster"><span>Apply the EKS components to the KOPS cluster</span></a>
          </li>
          <li>
            <a href="/disaster-recovery-scenarios.html#observations-of-incident"><span>Observations of Incident</span></a>
          </li>
          <li>
            <a href="/disaster-recovery-scenarios.html#destroy-the-eks-components"><span>Destroy the EKS components</span></a>
          </li>
          <li>
            <a href="/disaster-recovery-scenarios.html#re-apply-the-kops-components"><span>Re-apply the KOPS components</span></a>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>
<ul>
  <li>
    <a href="/replacing-live1.html#replacing-live-1-would-be-hard-because"><span>Replacing Live-1 Would be Hard Because‚Ä¶</span></a>
    <ul>
      <li>
        <a href="/replacing-live1.html#reasons-replacing-live-1-is-hard"><span>Reasons replacing live-1 is hard:</span></a>
      </li>
      <li>
        <a href="/replacing-live1.html#solved-issues"><span>Solved issues</span></a>
      </li>
    </ul>
  </li>
</ul>
<ul>
  <li>
    <a href="/rotate-user-aws-credentials.html#rotate-user-aws-credentials"><span>Rotate User AWS Credentials</span></a>
    <ul>
      <li>
        <ul>
          <li>
          </li>
        </ul>
      </li>
      <li>
        <a href="/rotate-user-aws-credentials.html#set-pingdom-environment-variables-optional"><span>Set pingdom environment variables(Optional)</span></a>
      </li>
      <li>
        <a href="/rotate-user-aws-credentials.html#target-the-live-1-cluster"><span>Target the live-1 cluster</span></a>
      </li>
      <li>
        <a href="/rotate-user-aws-credentials.html#set-cluster-related-environment-variables"><span>Set cluster related environment variables</span></a>
      </li>
      <li>
        <a href="/rotate-user-aws-credentials.html#set-the-namespace-name"><span>Set the namespace name</span></a>
      </li>
      <li>
        <a href="/rotate-user-aws-credentials.html#terraform-init"><span>Terraform Init</span></a>
      </li>
      <li>
        <a href="/rotate-user-aws-credentials.html#terraform-plan-apply"><span>Terraform Plan/Apply</span></a>
        <ul>
          <li>
            <a href="/rotate-user-aws-credentials.html#2-identify-the-compromised-terraform-object"><span>2. Identify the compromised terraform object</span></a>
          </li>
          <li>
            <a href="/rotate-user-aws-credentials.html#3-destroy-the-compromised-key"><span>3. Destroy the compromised key</span></a>
          </li>
          <li>
            <a href="/rotate-user-aws-credentials.html#4-let-terraform-create-a-new-key"><span>4. Let terraform create a new key</span></a>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>
<ul>
  <li>
    <a href="/aws-leaked-credentials.html#aws-compromised-credentials"><span>AWS Compromised Credentials</span></a>
    <ul>
      <li>
        <a href="/aws-leaked-credentials.html#steps-for-a-leaked-credentials"><span>Steps for a leaked credentials</span></a>
      </li>
      <li>
        <a href="/aws-leaked-credentials.html#getting-new-credentials"><span>Getting new credentials</span></a>
      </li>
    </ul>
  </li>
</ul>
<ul>
  <li>
    <a href="/aws-create-user.html#aws-console-access"><span>AWS Console Access</span></a>
    <ul>
      <li>
        <a href="/aws-create-user.html#steps-to-create-delete-users"><span>Steps to create/delete users</span></a>
      </li>
      <li>
        <a href="/aws-create-user.html#activating-mfa-for-new-users"><span>Activating MFA for new users</span></a>
      </li>
    </ul>
  </li>
</ul>
<ul>
  <li>
    <a href="/public-s3-bucket.html#make-an-s3-bucket-public"><span>Make an S3 bucket public</span></a>
  </li>
</ul>
<ul>
  <li>
    <a href="/delete-prometheus-metrics.html#delete-prometheus-metrics"><span>Delete Prometheus Metrics</span></a>
    <ul>
      <li>
        <a href="/delete-prometheus-metrics.html#1-identify-the-metrics-you-want-to-delete"><span>1.  Identify the metrics you want to delete</span></a>
      </li>
      <li>
        <a href="/delete-prometheus-metrics.html#2-enable-the-admin-interface-in-prometheus"><span>2. Enable the admin interface in Prometheus</span></a>
      </li>
      <li>
        <a href="/delete-prometheus-metrics.html#3-launch-a-port-forward-pod"><span>3. Launch a port-forward pod</span></a>
      </li>
      <li>
        <a href="/delete-prometheus-metrics.html#4-forward-local-traffic-to-prometheus"><span>4. Forward local traffic to Prometheus</span></a>
      </li>
      <li>
        <a href="/delete-prometheus-metrics.html#5-use-curl-in-another-terminal-to-hit-the-api-endpoint"><span>5. Use curl (in another terminal) to hit the API endpoint</span></a>
      </li>
      <li>
        <a href="/delete-prometheus-metrics.html#6-use-this-script-to-delete-multiple-metrics"><span>6. Use this script to delete multiple metrics</span></a>
      </li>
      <li>
        <a href="/delete-prometheus-metrics.html#7-clean-up"><span>7. Clean up</span></a>
      </li>
    </ul>
  </li>
</ul>
<ul>
  <li>
    <a href="/manually-apply-namespace.html#manually-plan-apply-namespace-resources"><span>Manually Plan/Apply Namespace Resources</span></a>
    <ul>
      <li>
        <a href="/manually-apply-namespace.html#start-in-the-appropriate-branch-of-the-environments-repo"><span>Start in the appropriate branch of the environments repo</span></a>
      </li>
      <li>
        <a href="/manually-apply-namespace.html#manually-plan-apply-namespace-resources-set-pingdom-environment-variables-optional"><span>Set pingdom environment variables(Optional)</span></a>
      </li>
      <li>
        <a href="/manually-apply-namespace.html#manually-plan-apply-namespace-resources-target-the-live-1-cluster"><span>Target the live-1 cluster</span></a>
      </li>
      <li>
        <a href="/manually-apply-namespace.html#set-some-environment-variables"><span>Set some environment variables</span></a>
      </li>
      <li>
        <a href="/manually-apply-namespace.html#manually-plan-apply-namespace-resources-set-the-namespace-name"><span>Set the namespace name</span></a>
      </li>
      <li>
        <a href="/manually-apply-namespace.html#manually-plan-apply-namespace-resources-terraform-init"><span>Terraform Init</span></a>
      </li>
      <li>
        <a href="/manually-apply-namespace.html#manually-plan-apply-namespace-resources-terraform-plan-apply"><span>Terraform Plan/Apply</span></a>
      </li>
    </ul>
  </li>
</ul>
<ul>
  <li>
    <a href="/manually-delete-namespace-resources.html#manually-delete-namespace-resources"><span>Manually Delete Namespace Resources</span></a>
  </li>
</ul>
<ul>
  <li>
    <a href="/export-elasticsearch-to-csv.html#export-data-from-elasticsearch-into-a-csv-file"><span>Export data from Elasticsearch into a CSV file</span></a>
    <ul>
      <li>
        <a href="/export-elasticsearch-to-csv.html#workaround"><span>Workaround</span></a>
        <ul>
          <li>
            <a href="/export-elasticsearch-to-csv.html#install-es2csv"><span>Install es2csv</span></a>
          </li>
          <li>
            <a href="/export-elasticsearch-to-csv.html#usage"><span>Usage</span></a>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>
<ul>
  <li>
    <a href="/remove-data-from-elasticsearch.html#remove-data-from-elasticsearch"><span>Remove data from Elasticsearch</span></a>
    <ul>
      <li>
        <a href="/remove-data-from-elasticsearch.html#stop-the-breach-first"><span>Stop the breach first</span></a>
      </li>
      <li>
        <a href="/remove-data-from-elasticsearch.html#things-to-know"><span>Things to know</span></a>
      </li>
      <li>
        <a href="/remove-data-from-elasticsearch.html#build-your-query"><span>Build your query</span></a>
      </li>
      <li>
        <a href="/remove-data-from-elasticsearch.html#delete-by-query"><span>Delete by query</span></a>
      </li>
      <li>
        <a href="/remove-data-from-elasticsearch.html#removing-specific-logs-filtered-by-phrase"><span>Removing specific logs filtered by phrase</span></a>
      </li>
    </ul>
  </li>
</ul>
<ul>
  <li>
    <a href="/delete-state-lock.html#delete-terraform-state-lock"><span>Delete terraform state lock</span></a>
    <ul>
      <li>
        <a href="/delete-state-lock.html#command-line-method"><span>Command-line method</span></a>
      </li>
      <li>
        <a href="/delete-state-lock.html#aws-console-method"><span>AWS Console method</span></a>
      </li>
    </ul>
  </li>
</ul>
<ul>
  <li>
    <a href="/error-refreshing-state.html#terraform-state-lock-error-refreshing-state"><span>Terraform state lock - Error refreshing state</span></a>
  </li>
</ul>
<ul>
  <li>
    <a href="/divergence-error.html#how-to-investigate-divergence-errors"><span>How to Investigate Divergence Errors</span></a>
    <ul>
      <li>
        <a href="/divergence-error.html#reproduce-the-plan"><span>Reproduce the plan</span></a>
      </li>
    </ul>
  </li>
</ul>
<ul>
  <li>
    <a href="/replacing-failed-master-node.html#recover-from-an-etcd-failure"><span>Recover from an etcd failure</span></a>
    <ul>
      <li>
        <a href="/replacing-failed-master-node.html#recover-from-an-etcd-failure-pre-requisites"><span>Pre-requisites</span></a>
      </li>
      <li>
        <a href="/replacing-failed-master-node.html#identify-the-failed-master-node"><span>Identify the failed master node</span></a>
      </li>
      <li>
        <a href="/replacing-failed-master-node.html#remove-the-unhealthy-etcd-member"><span>Remove the unhealthy etcd member.</span></a>
      </li>
      <li>
        <a href="/replacing-failed-master-node.html#replacing-the-failed-master-via-kops"><span>Replacing the failed master via kops</span></a>
        <ul>
          <li>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>
<ul>
  <li>
    <a href="/recycle-node.html#recycle-node"><span>Recycle-node</span></a>
    <ul>
      <li>
        <a href="/recycle-node.html#guidance-for-the-cloud-platform-team-when-the-recycle-node-pipeline-job-fails"><span>Guidance for the Cloud Platform team, when the recycle-node pipeline job fails:</span></a>
      </li>
    </ul>
  </li>
</ul>
<ul>
  <li>
    <a href="/multiple-clusters.html#managing-multiple-kops-clusters"><span>Managing Multiple Kops Clusters</span></a>
    <ul>
      <li>
        <a href="/multiple-clusters.html#overview"><span>Overview</span></a>
      </li>
      <li>
        <a href="/multiple-clusters.html#components-installed-only-in-live-1-cluster"><span>Components installed only in live-1 cluster</span></a>
      </li>
    </ul>
  </li>
</ul>
<ul>
  <li>
    <a href="/eks-cluster.html#provisioning-eks-clusters"><span>Provisioning EKS clusters</span></a>
    <ul>
      <li>
        <a href="/eks-cluster.html#provisioning-eks-clusters-pre-requisites"><span>Pre-requisites</span></a>
      </li>
      <li>
        <a href="/eks-cluster.html#provisioning"><span>Provisioning</span></a>
        <ul>
          <li>
            <a href="/eks-cluster.html#1-vpc"><span>1. VPC</span></a>
          </li>
          <li>
            <a href="/eks-cluster.html#2-creating-eks-cluster"><span>2. Creating EKS cluster</span></a>
          </li>
          <li>
            <a href="/eks-cluster.html#3-deploy-components"><span>3. Deploy components</span></a>
          </li>
          <li>
            <a href="/eks-cluster.html#4-delete-the-eks-cluster"><span>4. Delete the EKS cluster</span></a>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>
<ul>
  <li>
    <a href="/post-migration.html#post-migration-cleanup"><span>Post migration cleanup</span></a>
    <ul>
      <li>
        <a href="/post-migration.html#table-of-contents"><span>Table of contents</span></a>
      </li>
      <li>
        <a href="/post-migration.html#when-to-use-this-document"><span>When to use this document?</span></a>
      </li>
      <li>
        <a href="/post-migration.html#0-pre-requisites"><span>0. Pre-requisites</span></a>
        <ul>
          <li>
          </li>
        </ul>
      </li>
      <li>
        <a href="/post-migration.html#1-turn-off-template-deploy-monitoring-and-alerting"><span>1. Turn off Template Deploy monitoring and alerting</span></a>
        <ul>
          <li>
          </li>
        </ul>
      </li>
      <li>
        <a href="/post-migration.html#2-archive-the-deployment-repository"><span>2. Archive the deployment repository</span></a>
        <ul>
          <li>
          </li>
        </ul>
      </li>
      <li>
        <a href="/post-migration.html#3-backup-old-template-deploy-data"><span>3. Backup old Template Deploy data</span></a>
        <ul>
          <li>
          </li>
        </ul>
      </li>
      <li>
        <a href="/post-migration.html#4-delete-the-old-cloudformation-stack"><span>4. Delete the old CloudFormation stack</span></a>
        <ul>
          <li>
          </li>
        </ul>
      </li>
      <li>
        <a href="/post-migration.html#5-ensure-removal-of-resources"><span>5. Ensure removal of resources</span></a>
        <ul>
          <li>
          </li>
        </ul>
      </li>
      <li>
        <a href="/post-migration.html#6-ensure-live-service-is-still-functioning"><span>6. Ensure live service is still functioning!</span></a>
        <ul>
          <li>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>
<ul>
  <li>
    <a href="/expand.html#expanding-persistent-volumes-created-using-statefulsets"><span>Expanding Persistent Volumes created using StatefulSets</span></a>
  </li>
</ul>
<ul>
  <li>
    <a href="/velero.html#velero-cluster-backups-and-disaster-recovery"><span>Velero - Cluster backups and disaster recovery</span></a>
    <ul>
      <li>
        <ul>
          <li>
          </li>
        </ul>
      </li>
      <li>
        <a href="/velero.html#backups"><span>Backups</span></a>
        <ul>
          <li>
            <a href="/velero.html#why"><span>Why?</span></a>
          </li>
          <li>
            <a href="/velero.html#what"><span>What?</span></a>
          </li>
          <li>
            <a href="/velero.html#how"><span>How?</span></a>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>
<ul>
  <li>
    <a href="/sonarqube-scan.html#sonarqube-code-quality-and-security-scanning"><span>Sonarqube - Code quality and security scanning</span></a>
    <ul>
      <li>
        <a href="/sonarqube-scan.html#sonarqube-scanning"><span>Sonarqube scanning</span></a>
        <ul>
          <li>
            <a href="/sonarqube-scan.html#sonarqube-scan-all-repositories"><span>Sonarqube scan all repositories</span></a>
          </li>
          <li>
            <a href="/sonarqube-scan.html#sonarqube-github-action"><span>Sonarqube Github Action</span></a>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>
<ul>
  <li>
    <a href="/running-kops-update-rollingupdate.html#running-kops-update-and-rollingupdate"><span>Running Kops Update and Rollingupdate</span></a>
    <ul>
      <li>
        <a href="/running-kops-update-rollingupdate.html#using-kops-to-change-the-cluster"><span>Using kops to change the cluster</span></a>
      </li>
      <li>
        <a href="/running-kops-update-rollingupdate.html#running-kops-update-and-rollingupdate-pre-requisites"><span>Pre-requisites</span></a>
      </li>
      <li>
        <a href="/running-kops-update-rollingupdate.html#updating-the-kops-state"><span>Updating the kops state</span></a>
        <ul>
          <li>
            <a href="/running-kops-update-rollingupdate.html#generating-an-updated-kops-config-file"><span>Generating an updated kops config file</span></a>
          </li>
          <li>
            <a href="/running-kops-update-rollingupdate.html#applying-local-changes-to-the-kops-state-store"><span>Applying local changes to the kops state store</span></a>
          </li>
        </ul>
      </li>
      <li>
        <a href="/running-kops-update-rollingupdate.html#running-kops-update"><span>Running Kops update</span></a>
      </li>
      <li>
        <a href="/running-kops-update-rollingupdate.html#running-kops-rolling-update"><span>Running Kops rolling-update</span></a>
      </li>
      <li>
        <a href="/running-kops-update-rollingupdate.html#possible-errors"><span>Possible Errors</span></a>
      </li>
    </ul>
  </li>
</ul>
<ul>
  <li>
    <a href="/helm-repository.html#cloud-platform-helm-chart-repository"><span>Cloud Platform helm chart repository</span></a>
    <ul>
      <li>
        <a href="/helm-repository.html#performing-crud-on-cloud-platform-helm-repository"><span>Performing CRUD on Cloud Platform Helm repository</span></a>
      </li>
    </ul>
  </li>
</ul>
<ul>
  <li>
    <a href="/access-eks-cluster.html#access-eks-cluster"><span>Access EKS cluster</span></a>
    <ul>
      <li>
        <a href="/access-eks-cluster.html#access-eks-cluster-pre-requisites"><span>Pre-requisites</span></a>
        <ul>
          <li>
            <a href="/access-eks-cluster.html#create-kubeconfig-using-aws-command"><span>Create kubeconfig using aws command</span></a>
          </li>
          <li>
            <a href="/access-eks-cluster.html#create-kubeconfig-manually-using-a-template"><span>Create kubeconfig manually using a template</span></a>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>
<ul>
  <li>
    <a href="/auth-keys.html#how-to-add-authorized-keys"><span>How to add authorized keys</span></a>
  </li>
</ul>
<ul>
  <li>
    <a href="/custom-default-backend.html#custom-default-backend"><span>Custom default-backend</span></a>
    <ul>
      <li>
        <ul>
          <li>
            <a href="/custom-default-backend.html#background"><span>Background</span></a>
          </li>
          <li>
            <a href="/custom-default-backend.html#use-platform-level-error-page"><span>Use platform-level error page</span></a>
          </li>
          <li>
            <a href="/custom-default-backend.html#not-use-platform-level-error-page"><span>Not use platform-level error page</span></a>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>
<ul>
  <li>
    <a href="/joiners-guide.html#onboarding-into-the-cloud-platform-team"><span>Onboarding into the Cloud Platform Team</span></a>
    <ul>
      <li>
        <a href="/joiners-guide.html#people-team"><span>People Team</span></a>
      </li>
      <li>
        <a href="/joiners-guide.html#service-desk"><span>Service Desk</span></a>
      </li>
      <li>
        <a href="/joiners-guide.html#sit-down-with-dm"><span>Sit down with DM</span></a>
      </li>
      <li>
        <a href="/joiners-guide.html#cloud-platform-team"><span>Cloud Platform team</span></a>
      </li>
      <li>
        <a href="/joiners-guide.html#access"><span>ACCESS</span></a>
      </li>
    </ul>
  </li>
</ul>
<ul>
  <li>
    <a href="/add-new-opa-policy.html#open-policy-agent-policies"><span>Open Policy Agent policies</span></a>
    <ul>
      <li>
        <a href="/add-new-opa-policy.html#adding-a-policy"><span>Adding a policy</span></a>
      </li>
      <li>
        <a href="/add-new-opa-policy.html#writing-tests"><span>Writing tests</span></a>
      </li>
      <li>
        <a href="/add-new-opa-policy.html#references"><span>References</span></a>
      </li>
    </ul>
  </li>
</ul>
<ul>
  <li>
    <a href="/cloud-platform-to-tgw.html#adding-a-route-to-connect-to-a-tgw"><span>Adding a route to connect to a TGW</span></a>
    <ul>
      <li>
        <a href="/cloud-platform-to-tgw.html#quick-introduction"><span>Quick introduction</span></a>
      </li>
      <li>
        <a href="/cloud-platform-to-tgw.html#transit-gateway"><span>Transit Gateway</span></a>
      </li>
      <li>
        <a href="/cloud-platform-to-tgw.html#making-the-change"><span>Making the change</span></a>
      </li>
    </ul>
  </li>
</ul>
<ul>
  <li>
    <a href="/destroy-concourse-build-data.html#destroy-concourse-build-data"><span>Destroy Concourse Build Data</span></a>
    <ul>
      <li>
        <a href="/destroy-concourse-build-data.html#destroy-concourse-build-data-overview"><span>Overview</span></a>
      </li>
      <li>
        <a href="/destroy-concourse-build-data.html#steps-to-remove-the-build-data"><span>Steps to remove the build data</span></a>
      </li>
    </ul>
  </li>
</ul>
<ul>
  <li>
    <a href="/leavers-guide.html#leavers-guide"><span>Leavers Guide</span></a>
    <ul>
      <li>
        <a href="/leavers-guide.html#revoking-access"><span>Revoking Access</span></a>
        <ul>
          <li>
            <a href="/leavers-guide.html#digital-services"><span>Digital Services</span></a>
          </li>
          <li>
            <a href="/leavers-guide.html#aws-accounts"><span>AWS Accounts</span></a>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>
<ul>
  <li>
    <a href="/scheduled-pr-reminders.html#scheduled-pr-reminders"><span>Scheduled PR Reminders</span></a>
    <ul>
      <li>
        <ul>
          <li>
            <a href="/scheduled-pr-reminders.html#steps-required-for-new-repositories"><span>Steps required for new repositories</span></a>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>
<ul>
  <li>
    <a href="/grafana-dashboards.html#grafana-dashboards"><span>Grafana Dashboards</span></a>
    <ul>
      <li>
        <a href="/grafana-dashboards.html#kubernetes-number-of-pods-per-node"><span>Kubernetes Number of Pods per Node</span></a>
        <ul>
          <li>
            <a href="/grafana-dashboards.html#dashboard-layout"><span>Dashboard Layout</span></a>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>
<ul>
  <li>
    <a href="/on-call.html#going-on-call"><span>Going on call</span></a>
    <ul>
      <li>
        <a href="/on-call.html#what-s-expected"><span>What‚Äôs expected?</span></a>
        <ul>
          <li>
            <a href="/on-call.html#expected"><span>Expected:</span></a>
          </li>
          <li>
            <a href="/on-call.html#not-expected"><span>Not Expected:</span></a>
          </li>
        </ul>
      </li>
      <li>
        <a href="/on-call.html#where-do-i-start"><span>Where do I start?</span></a>
      </li>
      <li>
        <a href="/on-call.html#what-do-i-get-for-being-on-call"><span>What do I get for being on call?</span></a>
      </li>
      <li>
        <a href="/on-call.html#civil-servants"><span>Civil servants</span></a>
      </li>
      <li>
        <a href="/on-call.html#contractors"><span>Contractors</span></a>
      </li>
    </ul>
  </li>
</ul>
<ul>
  <li>
    <a href="/cloud-platform-communications-plan.html#cloud-platform-communications-plan"><span>Cloud Platform Communications Plan</span></a>
    <ul>
      <li>
        <a href="/cloud-platform-communications-plan.html#the-plan"><span>The Plan</span></a>
      </li>
      <li>
        <a href="/cloud-platform-communications-plan.html#tips-on-format-of-communications"><span>Tips on format of communications</span></a>
        <ul>
          <li>
            <a href="/cloud-platform-communications-plan.html#tips-on-format-of-communications-examples"><span>Examples</span></a>
          </li>
          <li>
            <a href="/cloud-platform-communications-plan.html#things-to-include-in-incident-communications"><span>Things to include in incident communications</span></a>
          </li>
          <li>
            <a href="/cloud-platform-communications-plan.html#example"><span>Example</span></a>
          </li>
          <li>
            <a href="/cloud-platform-communications-plan.html#things-to-include-in-upgrade-communications"><span>Things to include in upgrade communications</span></a>
          </li>
          <li>
            <a href="/cloud-platform-communications-plan.html#tips-on-format-of-communications-example"><span>Example</span></a>
          </li>
        </ul>
      </li>
      <li>
        <a href="/cloud-platform-communications-plan.html#sharing-information-with-the-wider-ministry-of-justice-and-the-public"><span>Sharing information with the wider Ministry of Justice and the Public</span></a>
      </li>
    </ul>
  </li>
</ul>
<ul>
  <li>
    <a href="/tips-and-tricks.html#tips-and-tricks"><span>Tips and Tricks</span></a>
    <ul>
      <li>
        <a href="/tips-and-tricks.html#delete-an-rds-database-snapshot"><span>Delete an RDS database snapshot</span></a>
      </li>
      <li>
        <a href="/tips-and-tricks.html#check-the-expiration-date-of-the-ssl-certificate-for-a-live-domain"><span>Check the expiration date of the SSL certificate for a live domain</span></a>
      </li>
      <li>
        <a href="/tips-and-tricks.html#run-etcdctl-on-a-master-node"><span>Run etcdctl on a master node</span></a>
      </li>
      <li>
        <a href="/tips-and-tricks.html#delete-a-quot-stuck-quot-resource"><span>Delete a ‚Äústuck‚Äù resource</span></a>
      </li>
      <li>
        <a href="/tips-and-tricks.html#filter-namespaces-by-specific-label-or-annotation"><span>Filter namespaces by specific label or annotation</span></a>
      </li>
      <li>
        <a href="/tips-and-tricks.html#find-all-pods-running-on-a-specific-worker-node"><span>Find all pods running on a specific worker node</span></a>
      </li>
      <li>
        <a href="/tips-and-tricks.html#count-pods-running-on-all-nodes"><span>Count pods running on all nodes</span></a>
      </li>
      <li>
        <a href="/tips-and-tricks.html#install-tmux-and-docker-on-the-live-1-bastion-host"><span>Install tmux and docker on the live-1 bastion host</span></a>
      </li>
      <li>
        <a href="/tips-and-tricks.html#output-all-records-from-route53-as-a-csv-file"><span>Output all records from Route53 as a CSV file</span></a>
      </li>
      <li>
        <a href="/tips-and-tricks.html#add-more-rss-feeds-to-cloud-platform-rss-channel"><span>Add more RSS feeds to #cloud-platform-rss channel</span></a>
      </li>
      <li>
        <a href="/tips-and-tricks.html#find-files-which-don-39-t-contain-a-particular-string"><span>Find files which don‚Äôt contain a particular string</span></a>
      </li>
      <li>
        <a href="/tips-and-tricks.html#get-aws-ec2-instance-information-for-a-node"><span>Get AWS EC2 instance information for a node</span></a>
      </li>
      <li>
        <a href="/tips-and-tricks.html#create-a-one-off-job-to-repeat-a-cronjob"><span>Create a one-off job to repeat a cronjob</span></a>
      </li>
      <li>
        <a href="/tips-and-tricks.html#hijack-a-concourse-job-container"><span>Hijack a concourse job container</span></a>
      </li>
      <li>
        <a href="/tips-and-tricks.html#help-when-manually-deleting-aws-resources"><span>Help when manually deleting AWS resources</span></a>
      </li>
      <li>
        <a href="/tips-and-tricks.html#find-out-why-your-namespace-isn-39-t-deleting"><span>Find out why your namespace isn‚Äôt deleting</span></a>
      </li>
    </ul>
  </li>
</ul>
<ul>
  <li>
    <a href="/template-deploy-run-books.html#template-deploy-runbooks"><span>Template-deploy Runbooks</span></a>
    <ul>
      <li>
        <a href="/template-deploy-run-books.html#general-incident-procedure"><span>General Incident Procedure</span></a>
      </li>
      <li>
        <a href="/template-deploy-run-books.html#existing-runbooks"><span>Existing Runbooks</span></a>
      </li>
    </ul>
  </li>
</ul>
<ul>
  <li>
    <a href="/add-a-new-runbook.html#add-a-new-runbook"><span>Add a new runbook</span></a>
    <ul>
      <li>
        <ul>
          <li>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>


              </nav>
            </div>
          </div>

        <div class="app-pane__content toc-open-disabled">
          <main id="content" class="technical-documentation" data-module="anchored-headings">
              <h1 id="incident-log">Incident Log</h1>
<blockquote>
<p>Use the <a href="https://github.com/ministryofjustice/cloud-platform/blob/main/runbooks/bin/mean-time-to-repair.rb">mean-time-to-repair.rb</a> script to view performance metrics</p>
</blockquote>
<h2 id="q2-2021-apr-may">Q2 2021 (Apr-May)</h2>
<ul>
<li><p><strong>Mean Time to Repair</strong>: 2h 32m</p></li>
<li><p><strong>Mean Time to Resolve</strong>: 2h 44m</p></li>
</ul>
<h3 id="incident-on-2021-07-12-15-24-all-ingress-resources-using-apps-live-1-domain-names-stop-working">Incident on 2021-07-12 15:24 - All ingress resources using *apps.live-1 domain names stop working</h3>
<ul>
<li><p><strong>Key events</strong></p>

<ul>
<li>First detected 2021-07-12 15:44</li>
<li>Repaired 2021-07-12 15:51</li>
<li>Incident declared 2021-07-12 16:09</li>
<li>Resolved 2021-07-13 11:49</li>
</ul></li>
<li><p><strong>Time to repair</strong>: 0h 07m</p></li>
<li><p><strong>Time to resolve</strong>: 20h 03m</p></li>
<li><p><strong>Identified</strong>: User reported in #ask-cloud-platform an error from the APM monitoring platform Sentry:
<code>Hostname/IP does not match certificate&#39;s altnames</code></p></li>
<li><p><strong>Impact</strong>: All ingress resources using the *apps.live-1.cloud-platform.service.justice.gov.uk have mismatched certificates.</p></li>
<li><p><strong>Context</strong>:</p>

<ul>
<li>Occurred immediately following an upgrade to the default certificate of &ldquo;live&rdquo; clusters (PR here: https://github.com/ministryofjustice/cloud-platform-terraform-ingress-controller/pull/20)</li>
<li>The change amended the default certificate in the <code>live-1</code> cluster to <code>*.apps.manager.cloud-platform.service.justice.gov.uk</code>.</li>
<li>Slack thread: <a href="https://mojdt.slack.com/archives/C57UPMZLY/p1626101058045600">#ask-cloud-platform</a> for the incident, <a href="https://mojdt.slack.com/archives/C514ETYJX/p1626173354336900?thread_ts=1626101869.307700&amp;cid=C514ETYJX">#cloud-platform</a> for the recovery.</li>
</ul></li>
<li><p><strong>Resolution</strong>:</p>

<ul>
<li>The immediate repair was simple: perform an inline edit of the default certificate in <code>live-1</code>. Replacing the word <code>manager</code> with <code>live-1</code> i.e. reverting the faulty change.</li>
<li>Further investigation ensued, finding the cause of the incident was actually an underlying bug in the infrastructure apply pipeline used to perform a <code>terraform apply</code> against manager.</li>
<li>This bug had been around from the creation of the pipeline but had never surfaced.</li>
<li>The pipeline uses an environment variable named <code>KUBE_CTX</code> to context switch between clusters. This works for resources using the <code>terraform provider</code>, however, not for <code>null_resources</code>, causing the change in the above PR to apply to the wrong cluster.</li>
</ul></li>
<li><p><strong>Review actions</strong>:</p>

<ul>
<li>In the <a href="https://github.com/ministryofjustice/cloud-platform-cli">cloud-platform-cli</a>, create an assertion to ensure the cluster name is equal to the terraform workspace name.</li>
<li>Before the creation of Terraform resources, add a function in the cli to perform a <code>kubectl context</code> switch to the correct cluster.</li>
</ul></li>
</ul>
<h3 id="incident-on-2021-06-09-12-47-all-users-are-unable-to-create-new-ingress-rules-following-bad-modsec-ingress-controller-upgrade">Incident on 2021-06-09 12:47 - All users are unable to create new ingress rules, following bad ModSec Ingress-controller upgrade</h3>
<ul>
<li><p><strong>Key events</strong></p>

<ul>
<li>First detected 2021-06-09 13:15</li>
<li>Repaired 2021-06-09 13:46</li>
<li>Incident declared 2020-06-09 13:54</li>
<li>Resolved 2021-06-09 13:58</li>
</ul></li>
<li><p><strong>Time to repair</strong>: 0h 31m</p></li>
<li><p><strong>Time to resolve</strong>: 0h 43m</p></li>
<li><p><strong>Identified</strong>: User reported in #ask-cloud-platform an error when deploying UAT application:
<code>kind Ingress: Internal error occurred: failed calling webhook &quot;validate.nginx.ingress.kubernetes.io&quot;: Post https://modsec01-nx-modsec-admission.ingress-controllers.svc:443/networking/v1beta1/ingresses?timeout=10s: x509: certificate is valid for modsec01-nx-controller-admission, modsec01-nx-controller-admission.ingress-controllers.svc, not modsec01-nx-modsec-admission.ingress-controllers.svc</code></p></li>
<li><p><strong>Impact</strong>: It blocked all ingress API calls, so no new ingresses could be created, nor changes to current ingresses could be deployed, which included all user application deployments.</p></li>
<li><p><strong>Context</strong>:</p>

<ul>
<li>Occurred immediately following an upgrade to the ModSec Ingress-controller module v3.33.0, which apparently successfully deployed</li>
<li>It caused any new ingress or changes to current ingresses to be blocked by the ModSec Validation webhook</li>
<li>Timeline: <a href="https://docs.google.com/document/d/1s5pos29Gcq0ssVnpf0biqG2aE-Kt2PtyxEcpjG88rdc/edit#">Timeline</a> for the incident.</li>
<li>Slack thread: <a href="https://mojdt.slack.com/archives/C57UPMZLY/p1623240948285500">#ask-cloud-platform</a> for the incident, <a href="https://mojdt.slack.com/archives/C514ETYJX/p1623242510212300">#cloud-platform</a> for the recovery.</li>
</ul></li>
<li><p><strong>Resolution</strong>: Rollback to ModSec Ingress-controller module v0.0.7</p></li>
<li><p><strong>Review actions</strong>:</p>

<ul>
<li>Find out why this issue didn‚Äôt get flagged in the test cluster - try to reproduce the issue - maybe need another test? Ticket <a href="https://github.com/ministryofjustice/cloud-platform/issues/2972">#2972</a></li>
<li>Add test that checks the alerts in alertmanager in smoke tests. Ticket <a href="https://github.com/ministryofjustice/cloud-platform/issues/2973">#2973</a></li>
<li>Add helloworld app that uses modsec controller, for the smoke tests to check traffic works. Ticket <a href="https://github.com/ministryofjustice/cloud-platform/issues/2974">#2974</a></li>
<li>Modsec module, new version, needs to be working on EKS for live-1 and live (neither old or new version work on live). Ticket <a href="https://github.com/ministryofjustice/cloud-platform/issues/2975">#2975</a></li>
</ul></li>
</ul>
<h3 id="incident-on-2021-05-10-12-15-apply-pipeline-downtime-due-to-accidental-destroy-of-manager-cluster">Incident on 2021-05-10 12:15 - Apply Pipeline downtime due to accidental destroy of Manager cluster</h3>
<ul>
<li><p><strong>Key events</strong></p>

<ul>
<li>First detected 2021-05-10 12:15</li>
<li>Incident not declared, but later agreed it was one</li>
<li>Repaired 2021-05-10 16:48</li>
<li>Resolved 2021-05-11 10:00</li>
</ul></li>
<li><p><strong>Time to repair</strong>: 4h 33m</p></li>
<li><p><strong>Time to resolve</strong>: 4h 45m</p></li>
<li><p><strong>Identified</strong>: CP team member did &lsquo;terraform destroy components&rsquo;, intending it to destroy a test cluster, but it was on Manager cluster by mistake. Was immediately aware of the error.</p></li>
<li><p><strong>Impact</strong>:</p>

<ul>
<li>Users couldn&rsquo;t create or change their namespace definitions or AWS resources, due to Concourse being down</li>
</ul></li>
<li><p><strong>Context</strong>:</p>

<ul>
<li>Timeline: <a href="https://docs.google.com/document/d/1rrROMuq5D6wajAPZGy3sq_P98ZmvMmaHygWKUgLyTCM/edit#">Timeline</a> for the incident</li>
<li>Slack thread: <a href="https://mojdt.slack.com/archives/C514ETYJX/p1620645898320200">Slack thread</a> for the incident.</li>
</ul></li>
<li><p><strong>Resolution</strong>:</p>

<ul>
<li>Manager cluster was recreated.</li>
<li>During this we encountered a certificate issue with Concourse, so it was restored manually. The terraform had got out of date for the Manager cluster.</li>
<li>Route53 zones were hard-coded and had to be <a href="https://github.com/ministryofjustice/cloud-platform-infrastructure/pull/1162/files">changed manually</a>.</li>
</ul></li>
<li><p><strong>Actions following review</strong>:</p>

<ul>
<li>Spike ways to avoid applying to wrong cluster - see 3 options above. Ticket <a href="https://github.com/ministryofjustice/cloud-platform/issues/3016">#3016</a></li>
<li>Try ‚ÄòPrevent destroy‚Äô setting on R53 zone - Ticket <a href="https://github.com/ministryofjustice/cloud-platform/issues/2899">#2899</a></li>
<li>Disband the cloud-platform-concourse repository. This includes Service accounts, and pipelines. We should split this repository up and move it to the infra/terraform-concourse repos. Ticket <a href="https://github.com/ministryofjustice/cloud-platform/issues/3017">#3017</a></li>
<li>Manager needs to use our PSPs instead of eks-privilege - this has already been done.</li>
</ul></li>
</ul>
<h2 id="q1-2021-january-march">Q1 2021 (January - March)</h2>
<ul>
<li><p><strong>Mean Time to Repair</strong>: N/A</p></li>
<li><p><strong>Mean Time to Resolve</strong>: N/A</p></li>
</ul>
<h3 id="no-incidents-declared">No incidents declared</h3><h2 id="q4-2020-october-december">Q4 2020 (October - December)</h2>
<ul>
<li><p><strong>Mean Time to Repair</strong>: 2h 8m</p></li>
<li><p><strong>Mean Time to Resolve</strong>: 8h 46m</p></li>
</ul>
<h3 id="incident-on-2020-10-06-09-07-intermittent-quot-micro-downtimes-quot-on-various-services-using-dedicated-ingress-controllers">Incident on 2020-10-06 09:07 - Intermittent &ldquo;micro-downtimes&rdquo; on various services using dedicated ingress controllers</h3>
<ul>
<li><p><strong>Key events</strong></p>

<ul>
<li>First detected 2020-10-06 08:33</li>
<li>Incident declared 2020-10-06 09:07</li>
<li>Repaired 2020-10-06 10:41</li>
<li>Resolved 2020-10-06 17:19</li>
</ul></li>
<li><p><strong>Time to repair</strong>: 2h 8m</p></li>
<li><p><strong>Time to resolve</strong>: 8h 46m</p></li>
<li><p><strong>Identified</strong>: User reported service problems in #ask-cloud-platform. Confirmed by checking Pingdom</p></li>
<li><p><strong>Impact</strong>:</p>

<ul>
<li>Numerous brief and intermittent outages for multiple (but not all) services (production and non-production) which were using dedicated ingress controllers</li>
</ul></li>
<li><p><strong>Context</strong>:</p>

<ul>
<li>Occurred immediately after upgrading live-1 to kubernetes 1.17</li>
<li>1.17 creates 2 additional SecurityGroupRules per ingress-controller, this took us over a hard AWS limit</li>
<li>Timeline: <a href="https://docs.google.com/document/d/108pSsVxt_YJFj2jrY86dIvuuP8g8j5aLFsMdlb1YMeI/edit#heading=h.z8h3a4mkgult">Timeline</a> for the incident.</li>
<li>Slack thread: <a href="https://mojdt.slack.com/archives/C514ETYJX/p1601971645475700">Slack thread</a> for the incident.</li>
</ul></li>
<li><p><strong>Resolution</strong>:</p>

<ul>
<li>Migrate all ingresses back to the default ingress controller</li>
</ul></li>
</ul>
<h2 id="q3-2020-july-september">Q3 2020 (July - September)</h2>
<ul>
<li><p><strong>Mean Time To Repair</strong>: 1h 9m</p></li>
<li><p><strong>Mean Time To Resolve</strong>: 7h 26m</p></li>
</ul>
<h3 id="incident-on-2020-09-28-13-10-termination-of-nodes-updating-kops-instance-group">Incident on 2020-09-28 13:10 - Termination of nodes updating kops Instance Group.</h3>
<ul>
<li><p><strong>Key events</strong></p>

<ul>
<li>First detected 2020-09-28 13:14</li>
<li>Incident declared 2020-09-28 14:05</li>
<li>Repaired 2020-09-28 14:20</li>
<li>Resolved 2020-09-28 14:44</li>
</ul></li>
<li><p><strong>Time to repair</strong>: 0h 15m</p></li>
<li><p><strong>Time to resolve</strong>: 1h 30m</p></li>
<li><p><strong>Identified</strong>: Periods of downtime while the cloud-platform team was applying per Availability Zone instance groups for worker nodes change in live-1. Failures caused mainly due to termination of a group of 9 nodes and letting kops to handle the cycling of pods, which took very long time for the new containers to be created in the new node group.</p></li>
<li><p><strong>Impact</strong>:</p>

<ul>
<li>Some users noticed cycling of pods but taking a long time for the containers to be created.</li>
<li>Prometheus/alertmanager/kibana health check failures.</li>
<li>Users noticed short-lived pingdom alerts &amp; health check failures.</li>
</ul></li>
<li><p><strong>Context</strong>:</p>

<ul>
<li>kops node group (nodes-1.16.13) updated minSize from 25 to 18 nodes and ran kops update cluster &ndash;yes, this terminated 9 nodes from existing worker node  group (nodes-1.16.13).</li>
<li>Pods are in pending status for a long time waiting to be scheduled in the new nodes.</li>
<li>Teams using their own ingress-controller have 1 replica for non-prod namespaces, causing some pingdom alerts &amp; health check failures.</li>
<li>Timeline: <a href="https://docs.google.com/document/d/1ysz7KYjFrZ7YJ3QhyWQGvbgoPW8D0XHJpMgfJB6g2hc/edit#heading=h.ttkde0ugh32m">Timeline</a> for the incident.</li>
<li>Slack thread: <a href="https://mojdt.slack.com/archives/C514ETYJX/p1601298352147700">Slack thread</a> for the incident.</li>
</ul></li>
<li><p><strong>Resolution</strong>:</p>

<ul>
<li>This is resolved by cordoning and draining nodes one by one before deleting the instance group.</li>
</ul></li>
</ul>
<h3 id="incident-on-2020-09-21-18-27-some-cloud-platform-components-destroyed">Incident on 2020-09-21 18:27 - Some cloud-platform components destroyed.</h3>
<ul>
<li><p><strong>Key events</strong></p>

<ul>
<li>First detected 2020-09-21 18:27</li>
<li>Incident declared 2020-09-21 18:40</li>
<li>Repaired 2020-09-21 19:05</li>
<li>Resolved 2020-09-21 21:41</li>
</ul></li>
<li><p><strong>Time to repair</strong>: 0h 38m</p></li>
<li><p><strong>Time to resolve</strong>: 3h 14m</p></li>
<li><p><strong>Identified</strong>: Some components of our production kubernetes cluster (live-1) were accidentally deleted, this caused some services running on cloud-platform gone down.</p></li>
<li><p><strong>Impact</strong>:</p>

<ul>
<li>Some users could not access services running on the Cloud Platform.</li>
<li>Prometheus/alertmanager/grafana is not accessible.</li>
<li>kibana is not accessible.</li>
<li>Cannot create new certificates.</li>
</ul></li>
<li><p><strong>Context</strong>:</p>

<ul>
<li>Test cluster deletion script triggered to delete a test cluster, kube context incorrectly targeted the live-1 cluster and deleted some cloud-platform components.</li>
<li>Components include default ingress-controller, prometheus-operator, logging, cert-manager, kiam and external-dns. As ingress-controller gone down some users could not access services running on the Cloud Platform.</li>
<li>Formbuilder services not accessible even after ingress-controller is restored.</li>
<li>Timeline: <a href="https://docs.google.com/document/d/1nmhFcLkOEmyvN2E7PwUdo8l2O9EDpVx7c8-4d9pMBSg/edit#heading=h.ttkde0ugh32m">Timeline</a> for the incident.</li>
<li>Slack thread: <a href="https://mojdt.slack.com/archives/C514ETYJX/p1600710001173700">Slack thread</a> for the incident.</li>
</ul></li>
<li><p><strong>Resolution</strong>:</p>

<ul>
<li>Team prioritised to restore default ingress controller, ingress-controller has a dependency of external-dns to update route53 records with
new NLB and kiam for providing AWSAssumeRole for external-dns, these components (ingress-controller, external-dns and kiam) got restored successfully. Services start to come back up.</li>
<li>Formbuilder services are still pointing to the old NLB (network load balancer before ingress got replaced), reason for this is route53 TXT records was set incorrect owner field, so external-dns couldn&rsquo;t update the new NLB information in the A record. Team fixed the owner information in the TXT record, external DNS updated formbuilder route53 records to point to new NLB. Formbuilder services is up and running.</li>
<li>Team did target apply to restore remaining components.</li>
<li>Apply pipleine run to restore all the certificates, servicemonitors and prometheus-rules from the <a href="https://github.com/ministryofjustice/cloud-platform-environments">environment repository</a>.</li>
</ul></li>
</ul>
<h3 id="incident-on-2020-09-07-12-54-all-users-are-unable-to-create-new-ingress-rules">Incident on 2020-09-07 12:54 - All users are unable to create new ingress rules</h3>
<ul>
<li><p><strong>Key events</strong></p>

<ul>
<li>First detected 2020-09-07 12:39</li>
<li>Incident declared 2020-09-07 12:54</li>
<li>Resolved 2020-09-07 15:56</li>
</ul></li>
<li><p><strong>Time to repair</strong>: 3h 02m</p></li>
<li><p><strong>Time to resolve</strong>: 3h 17m</p></li>
<li><p><strong>Identified</strong>: The Ingress API refused 100% of POST requests.</p></li>
<li><p><strong>Impact</strong>:</p>

<ul>
<li>If a user were to provision a new service, they would be unable to create an ingress into the cluster.</li>
</ul></li>
<li><p><strong>Context</strong>:</p>

<ul>
<li><a href="https://github.com/ministryofjustice/cloud-platform-terraform-teams-ingress-controller/compare/0.0.9...0.1.0">Version 0.1.0</a> of the <a href="https://github.com/ministryofjustice/cloud-platform-terraform-teams-ingress-controller">teams ingress controller module</a> enabled the creation of a <code>validationwebhookconfiguration</code> resource.</li>
<li>By enabling this option we created a single point of failure for all ingress-controller pods in the <code>ingress-controller</code> namespace.</li>
<li>A new 0.1.0 ingress controller failed to create in the &ldquo;live-1&rdquo; cluster due to AWS resource limits.</li>
<li>Validation webhook stopped new rules from creating, with the error:
<code>
Error from server (InternalError): error when creating &quot;ingress.yaml&quot;: Internal error occurred: failed calling webhook &quot;validate.nginx.ingress.kubernetes.io&quot;: Post https://offender-categorisation-prod-nx-controller-admission.ingress-controllers.svc:443/extensions/v1beta1/ingresses?timeout=30s: x509: certificate signed by unknown authority
</code></li>
<li>Initial investigation thread: https://mojdt.slack.com/archives/C514ETYJX/p1599478794246900</li>
<li>Incident declared: https://mojdt.slack.com/archives/C514ETYJX/p1599479640251900</li>
</ul></li>
<li><p><strong>Resolution</strong>:
The team manually removed the all the additional admission controllers created by 0.1.0. They then removed the admission webhook from the module and created a new release (0.1.1). All ingress modules currently on 0.1.0 were upgraded to the new release 0.1.1.</p></li>
</ul>
<h3 id="incident-on-2020-08-25-11-26-connectivity-issues-with-eu-west-2a">Incident on 2020-08-25 11:26 - Connectivity issues with eu-west-2a</h3>
<ul>
<li><p><strong>Key events</strong></p>

<ul>
<li>First detected 2020-08-25 11:01</li>
<li>Incident declared 2020-08-25 11:26</li>
<li>Resolved 2020-08-25 12:11</li>
</ul></li>
<li><p><strong>Time to repair</strong>: 0h 45m</p></li>
<li><p><strong>Time to resolve</strong>: 1h 10m</p></li>
<li><p><strong>Identified</strong>: The AWS  Availability Zones <code>eu-west-2a</code>, which contain some of our kubernetes nodes had an outage. API latency was elevated, some EC2 became unreachable and overall connectivity was unstable.</p></li>
<li><p><strong>Impact</strong>:</p>

<ul>
<li>Two kubernetes nodes became unreachable</li>
<li>No new node could be launched in eu-west-2a</li>
<li>Kubernetes had issues talking to some of these nodes, preventing some API calls to succeed (Pods were not terminating)</li>
<li>New pods were not able to pull their Docker images.</li>
</ul></li>
<li><p><strong>Context</strong>:</p>

<ul>
<li>Pods and Nodes sitting in other Availability Zones (b &amp; c) were not impacted</li>
<li>Slack threads: <a href="https://mojdt.slack.com/archives/C514ETYJX/p1598351210195200">Issue detected</a>, <a href="https://mojdt.slack.com/archives/C514ETYJX/p1598351210195200">Incident Declared</a>,</li>
<li>We now have 25 pods in the cluster, instead of 21</li>
</ul></li>
<li><p><strong>Resolution</strong>:
The incident was mitigated by deploying more 2-4 nodes in healthy Availability Zones, manually deleting the non-responding pods, and terminating the impacted nodes</p></li>
</ul>
<h3 id="incident-on-2020-08-14-11-01-ingress-controllers-crashlooping">Incident on 2020-08-14 11:01 - Ingress-controllers crashlooping</h3>
<ul>
<li><p><strong>Key events</strong></p>

<ul>
<li>First detected 2020-08-14 10:43</li>
<li>Incident declared 2020-08-14 11:01</li>
<li>Resolved 2020-08-14 11:38</li>
</ul></li>
<li><p><strong>Time to repair</strong>: 0h 37m</p></li>
<li><p><strong>Time to resolve</strong>: 0h 55m</p></li>
<li><p><strong>Identified</strong>: There are 6 replicas of the ingress-controller pod and 2 out of the 6 were crashlooping. A restart of the pods did not resolve the issue. As per a normal runbook process, a recycle of all pods was required. However after restarting pods 4 and 5, they also started to crashloop. The risk was when restarting pods 5 and 6 -  all 6 pods could be down and all ingresses down for the cluster.</p></li>
<li><p><strong>Impact</strong>:</p>

<ul>
<li>Increased risk for all ingresses failing in the cluster if all 6 ingress-controller pods are in a crashloop state.</li>
</ul></li>
<li><p><strong>Context</strong>:</p>

<ul>
<li>2 of the 6 ingress-controller pods crashlooping, after restart of 4 pods, 4 out of 6 pods crashlooping.</li>
<li>Issue was with the leader ingress-controller pod (which was not identified or restarted yet) and exhausting the shared memory.</li>
<li>After a restart of the leader ingress-controller pod, all other pods reverted back to a ready/running state.</li>
<li>Timeline : <a href="https://docs.google.com/document/d/1kxKwC1B_pnlPbysS0zotbXMKyZcUDmDtnGbEyIHGvgQ/edit#heading=h.z3py6eydx4qu">https://docs.google.com/document/d/1kxKwC1B_pnlPbysS0zotbXMKyZcUDmDtnGbEyIHGvgQ/edit#heading=h.z3py6eydx4qu</a></li>
<li>Slack thread: <a href="https://mojdt.slack.com/archives/C514ETYJX/p1597399295031000">https://mojdt.slack.com/archives/C514ETYJX/p1597399295031000</a>,</li>
</ul></li>
<li><p><strong>Resolution</strong>:
A restart of the leader ingress-controller pod was required so the other pods in the replica-set could connect and get the latest nginx.config file.</p></li>
</ul>
<h3 id="incident-on-2020-08-07-16-39-master-node-provisioning-failure">Incident on 2020-08-07 16:39 - Master node provisioning failure</h3>
<ul>
<li><p><strong>Key events</strong></p>

<ul>
<li>First detected 2020-08-07 15:51</li>
<li>Repaired 2020-08-07 16:29</li>
<li>Incident declared 2020-08-07 16:39</li>
<li>Resolved 2020-08-14 10:06</li>
</ul></li>
<li><p><strong>Time to repair</strong>: 0h 38m</p></li>
<li><p><strong>Time to resolve</strong>: 33h 15m (during support hours 10:00-17:00 M-F)</p></li>
<li><p><strong>Identified</strong>: Routine replacement of a master node failed because AWS did not have any c4.4xlarge instances available in the relevant availability zone.</p></li>
<li><p><strong>Impact</strong>:</p>

<ul>
<li>Increased risk because the cluster was running on 2 out of 3 master nodes, for a brief period</li>
</ul></li>
<li><p><strong>Context</strong>:</p>

<ul>
<li>Lack of availability of a given instance type is not a failure mode for which we have planned</li>
<li>In theory, if a problem occurs which eventually kills each master node in turn, and if instances of the right type are not available in at least 2 availability zones, this could bring down the whole cluster.</li>
<li>Timeline : <a href="https://docs.google.com/document/d/1SOAOeL-89cuK-_fJbtgYcArInWQY7UXiIDY7wN5gjuA/edit#">https://docs.google.com/document/d/1SOAOeL-89cuK-_fJbtgYcArInWQY7UXiIDY7wN5gjuA/edit#</a>
ttps://docs.google.com/document/d/1kxKwC1B_pnlPbysS0zotbXMKyZcUDmDtnGbEyIHGvgQ/edit#heading=h.z3py6eydx4qu)</li>
<li>Slack thread: <a href="https://mojdt.slack.com/archives/C514ETYJX/p1596814746202600">https://mojdt.slack.com/archives/C514ETYJX/p1596814746202600</a></li>
</ul></li>
<li><p><strong>Resolution</strong>:</p>

<ul>
<li>A new c4.4xlarge node <em>was</em> successfully (and automatically) launched approx. 40 minutes after we saw the problem</li>
<li>We replaced all our master nodes with c5.4xlarge instances, which (currently) have better availability</li>
<li>We and AWS are still investigating longer-term and more reliable fixes</li>
</ul></li>
</ul>
<h2 id="q2-2020-april-june">Q2 2020 (April - June)</h2>
<ul>
<li><p><strong>Mean Time To Repair</strong>: 2h 5m</p></li>
<li><p><strong>Mean Time To Resolve</strong>: 15h 53m</p></li>
</ul>
<h3 id="incident-on-2020-08-04-17-13">Incident on 2020-08-04 17:13</h3>
<ul>
<li><p><strong>Key events</strong></p>

<ul>
<li>Fault occurs 2020-08-04 13:30</li>
<li>Fault detected 2020-08-04 18:13</li>
<li>Incident declared 2020-08-05 11:04</li>
<li>Resolved 2020-08-05 16:16</li>
</ul></li>
<li><p><strong>Time to repair</strong>: 5h 8m</p></li>
<li><p><strong>Time to resolve</strong>: 9h 16m (during support hours 10:00-17:00)</p></li>
<li><p><strong>Identified</strong>: Integration tests failed for cert-manager, apply pipeline failed showing it doesnot have permissions and
divergence pipeline shows drift for live-1 components</p></li>
<li><p><strong>Impact</strong>:</p>

<ul>
<li>Increased risk for cluster failure because some of the components do not have the correct configuration needed for the <code>live-1</code> production cluster</li>
</ul></li>
<li><p><strong>Context</strong>:</p>

<ul>
<li>One of the engineers was creating a test EKS cluster and ran <code>terraform apply</code> on EKS components</li>
<li>Without fully aware of the current cluster context, the <code>terraform apply</code> for EKS test cluster components has been applied to the <code>live-1</code> kops cluster</li>
<li>This has changed the configuration of several resources in the <code>live-1</code> cluster</li>
<li>Timeline : <a href="https://docs.google.com/document/d/1VrABxeHLMOnoM4yYoCi9N4N4zRY1SK1hTjrZ9s05zuc/edit?usp=sharing">https://docs.google.com/document/d/1VrABxeHLMOnoM4yYoCi9N4N4zRY1SK1hTjrZ9s05zuc/edit?usp=sharing</a></li>
<li>Slack thread: <a href="https://mojdt.slack.com/archives/C514ETYJX/p1596621864015400">https://mojdt.slack.com/archives/C514ETYJX/p1596621864015400</a>,</li>
</ul></li>
<li><p><strong>Resolution</strong>:
Compare each resource configuration with the terraform state and applied the correct configuration from the code specific to kops cluster</p></li>
</ul>
<h3 id="incident-on-2020-04-15-10-58-nginx-tls">Incident on 2020-04-15 10:58 Nginx/TLS</h3>
<ul>
<li><p><strong>Key events</strong></p>

<ul>
<li>Fault occurs 2020-04-15 07:15</li>
<li>Fault detected 2020-04-15 13:45</li>
<li>Incident declared 2020-04-15 14:39</li>
<li>Resolved 2020-04-15 15:09</li>
</ul></li>
<li><p><strong>Status</strong>: Resolved at 2020-04-15 15:09 UTC</p></li>
<li><p><strong>Time to repair</strong>: 0h 30m</p></li>
<li><p><strong>Time to resolve</strong>: 5h 09m (during support hours 10:00-17:00)</p></li>
<li><p><strong>Identified</strong>: After an upgrade of the Nginx ingresses, support for legacy TLS was dropped.</p></li>
<li><p><strong>Impact</strong>:</p>

<ul>
<li>IE11 users could not access any services running on the Cloud Platform</li>
<li>A few teams came forward with the issue :</li>
<li>LAA</li>
<li>Correspondence Tool</li>
<li>Prisoner Money</li>
</ul></li>
<li><p><strong>Context</strong>:</p>

<ul>
<li>After an upgrade of the Nginx Helm chart v1.24.0 to v1.35</li>
<li>The current version of Nginx has deprecated support for TLS &lt; 1.3</li>
<li>The issue was spotted on IE11 browsers.</li>
<li>Timeline : <a href="https://docs.google.com/document/d/1SCf1WT82IlBYWozWN_FXZqL5h0KUcul_QAkxE84YDw0/edit?usp=sharing">https://docs.google.com/document/d/1SCf1WT82IlBYWozWN_FXZqL5h0KUcul_QAkxE84YDw0/edit?usp=sharing</a></li>
<li>Slack thread: <a href="https://mojdt.slack.com/archives/C57UPMZLY/p1586954463298700">https://mojdt.slack.com/archives/C57UPMZLY/p1586954463298700</a></li>
</ul></li>
<li><p><strong>Resolution</strong>:
The Nginx configuration was modified to enable TLSv1, TLSv1.1 and TLSv1.2</p></li>
</ul>
<h2 id="q1-2020-january-march">Q1 2020 (January - March)</h2>
<ul>
<li><p><strong>Mean Time To Repair</strong>: 1h 22m</p></li>
<li><p><strong>Mean Time To Resolve</strong>: 2h 36m</p></li>
</ul>
<h3 id="incident-on-2020-02-25-10-58">Incident on 2020-02-25 10:58</h3>
<ul>
<li><p><strong>Key events</strong></p>

<ul>
<li>Fault occurs 2020-02-25 07:32</li>
<li>Team aware 2020-02-25 07:36</li>
<li>Incident declared 2020-02-25 10:58</li>
<li>Resolved 2020-02-25 17:07</li>
</ul></li>
<li><p><strong>Time to repair</strong>: 4h 9m</p></li>
<li><p><strong>Time to resolve</strong>: 7h (during support hours 10:00-17:00)</p></li>
<li><p><strong>Identified</strong>: During an upgrade, new masters were not coming up correctly (missing calico networking and other pods)</p></li>
<li><p><strong>Impact</strong>:</p>

<ul>
<li>Degraded kubernetes API performance (because some API calls were being directed to non-functioning masters)</li>
<li>Increased risk of cluster failure, because we were running on a single master during the incident</li>
</ul></li>
<li><p><strong>Context</strong>:</p>

<ul>
<li>Upgrading from kubernetes 1.13.12 to 1.14.10, kops 1.13.2 to 1.14.1</li>
<li>The first master was replaced fine, but the second didn&rsquo;t have calico and some other essential pods, and was not functioning correctly</li>
<li>Attempting to roll back the upgrade, every new master exhibited the same problem</li>
<li>Slack thread: <a href="https://mojdt.slack.com/archives/C514ETYJX/p1582628309085600">https://mojdt.slack.com/archives/C514ETYJX/p1582628309085600</a></li>
</ul></li>
<li><p><strong>Resolution</strong>:
The <code>kube-system</code> namespace has a label, <code>openpolicyagent.org/webhook: ignore</code> This label tells the Open Policy Agent (OPA) that pods are allowed to run in this namespace on the master nodes. Somehow, this label got removed, so the OPA was preventing pods from running on the new master nodes, as each one came up, so the new master was unable to launch essential pods such as <code>calico</code> and <code>fluentd</code>.</p></li>
</ul>
<h3 id="incident-on-2020-02-18-14-13-utc">Incident on 2020-02-18 14:13 UTC</h3>
<ul>
<li><p><strong>Key events</strong></p>

<ul>
<li>Fault occurs 2020-02-18 14:13</li>
<li>Incident declared 2020-02-18 14:23</li>
<li>Resolved 2020-02-18 14:59</li>
</ul></li>
<li><p><strong>Time to repair</strong>: 0h 36m</p></li>
<li><p><strong>Time to resolve</strong>: 0h 46m</p></li>
<li><p><strong>Identified</strong>: Pingdom reported that Prometheus was down (prometheus.cloud-platform.service.justice.gov.uk).</p></li>
<li><p><strong>Impact</strong>:</p>

<ul>
<li>The prometheus dashboard was unavailable for everyone, for the whole duration of the incident.</li>
<li>Between 2020-02-18 14:22 and 2020-02-18 14:26, prometheus could not receive metrics.</li>
</ul></li>
<li><p><strong>Context</strong>:</p>

<ul>
<li>Although the Prometheus URL was unreachable, Grafana and Alertmanager were resolving.</li>
<li>There seemed to be an issue preventing requests to reach the prometheus pods.</li>
<li>Disk space and other resources, the usual suspects, were ruled out as the cause.</li>
<li>The domain name amd ingress were both valid.</li>
<li>Slack thread: <a href="https://mojdt.slack.com/archives/C514ETYJX/p1582035803248800">https://mojdt.slack.com/archives/C514ETYJX/p1582035803248800</a></li>
</ul></li>
<li><p><strong>Resolution</strong>:
We suspect an intermittent &amp; external networking issue to be the cause of this outage.</p></li>
</ul>
<h3 id="incident-on-2020-02-12-11-45-utc">Incident on 2020-02-12 11:45 UTC</h3>
<ul>
<li><p><strong>Key events</strong></p>

<ul>
<li>Fault occurs 2020-02-12 11:45</li>
<li>Incident declared 2020-02-12 11:51</li>
<li>Resolved 2020-02-12 12:07</li>
</ul></li>
<li><p><strong>Time to repair</strong>: 0h 16m</p></li>
<li><p><strong>Time to resolve</strong>: 0h 22m</p></li>
<li><p><strong>Identified</strong>: Pingdom reported Concourse (concourse.cloud-platform.service.justice.gov.uk) down.</p></li>
<li><p><strong>Context</strong>:</p>

<ul>
<li>One of the engineers was deleting old clusters (he ran <code>terraform destroy</code>) and he wasn&rsquo;t fully aware in which <em>terraform workspace</em> was working on. Using <code>terraform destroy</code>, EKS nodes/workers were deleted from the manager cluster.</li>
<li>Slack thread: <a href="https://mojdt.slack.com/archives/C514ETYJX/p1581508273080900">https://mojdt.slack.com/archives/C514ETYJX/p1581508273080900</a></li>
<li><strong>Resolution</strong>: Using terraform (<code>terraform apply -var-file vars/manager.tfvars</code> specifically) the cluster nodes where created and the infrastructure aligned? to the desired terraform state</li>
</ul></li>
</ul>
<h2 id="about-this-incident-log">About this incident log</h2><p>The purpose of publishing this incident log:</p>

<ul>
<li>for the Cloud Platform team to learn from incidents</li>
<li>for the Cloud Platform team and its stakeholders to track incident trends and performance</li>
<li>because we operate in the open</li>
</ul>
<p>Definitions:</p>

<ul>
<li>The words used in the timeline of an incident: fault occurs, team becomes aware (of something bad), incident declared (the team acknowledges and has an idea of the impact), repaired (system is fully functional), resolved (fully functional and future failures are prevented)</li>
<li><em>Incident time</em> - The start of the failure (Before March 2020 it was the time the incident was declared)</li>
<li><em>Time to Repair</em> - The time between the incident being declared (or when the team became aware of the fault) and when service is fully restored. Only includes <a href="https://user-guide.cloud-platform.service.justice.gov.uk/documentation/reference/operational-processes.html#hours-of-support">Hours of Support</a>.</li>
<li><em>Time to Resolve</em> - The time between when the fault occurs and when system is fully functional (and include any immediate work done to prevent future failures). Only includes <a href="https://user-guide.cloud-platform.service.justice.gov.uk/documentation/reference/operational-processes.html#hours-of-support">Hours of Support</a>. This is a broader metric of incident response performance, compared to Time to Repair.</li>
</ul>
<p>Source: <a href="https://www.atlassian.com/incident-management/kpis/common-metrics">Atlassian</a></p>
<p>Datestamps: please use <code>YYYY-MM-DD HH:MM</code> (almost ISO 8601, but more readable), for the London timezone</p>
<h2 id="template">Template</h2><h3 id="incident-on-yyyy-mm-dd-hh-mm-brief-description">Incident on YYYY-MM-DD HH:MM - [Brief description]</h3>
<ul>
<li><p><strong>Key events</strong></p>

<ul>
<li>First detected YYYY-MM-DD HH:MM</li>
<li>Incident declared YYYY-MM-DD HH:MM</li>
<li>Repaired YYYY-MM-DD HH:MM</li>
<li>Resolved YYYY-MM-DD HH:MM</li>
</ul></li>
<li><p><strong>Time to repair</strong>: Xh Xm</p></li>
<li><p><strong>Time to resolve</strong>: Xh Xm</p></li>
<li><p><strong>Identified</strong>:</p></li>
<li><h2 id="impact"><strong>Impact</strong>:</h2></li>
<li><h2 id="context"><strong>Context</strong>:</h2>
<ul>
<li>Timeline: <a href="url%20of%20google%20document">Timeline</a> for the incident</li>
<li>Slack thread: <a href="url%20of%20primary%20incident%20thread">Slack thread</a> for the incident.</li>
</ul></li>
<li><h2 id="resolution"><strong>Resolution</strong>:</h2></li>
</ul>


            
          </main>

          <aside>
              <ul class="contribution-banner">
                <li><a href="https://github.com/ministryofjustice/cloud-platform/blob/main/runbooks/source/incident-log.html.md.erb">View source</a></li>
                <li><a href="https://github.com/ministryofjustice/cloud-platform/issues/new?labels=bug&amp;title=Re:%20'Incident%20Log'&amp;body=Problem%20with%20'Incident%20Log'%20(https://runbooks.cloud-platform.service.justice.gov.uk/incident-log.html)">Report problem</a></li>
                <li><a href="https://github.com/ministryofjustice/cloud-platform">GitHub Repo</a></li>
              </ul>
          </aside>

          <footer class="govuk-footer app-footer" role="contentinfo">
  <div class="govuk-footer__meta">
    <div class="govuk-footer__meta-item govuk-footer__meta-item--grow">


      <svg
        aria-hidden="true"
        focusable="false"
        class="govuk-footer__licence-logo"
        xmlns="http://www.w3.org/2000/svg"
        viewbox="0 0 483.2 195.7"
        height="17"
        width="41"
      >
        <path
          fill="currentColor"
          d="M421.5 142.8V.1l-50.7 32.3v161.1h112.4v-50.7zm-122.3-9.6A47.12 47.12 0 0 1 221 97.8c0-26 21.1-47.1 47.1-47.1 16.7 0 31.4 8.7 39.7 21.8l42.7-27.2A97.63 97.63 0 0 0 268.1 0c-36.5 0-68.3 20.1-85.1 49.7A98 98 0 0 0 97.8 0C43.9 0 0 43.9 0 97.8s43.9 97.8 97.8 97.8c36.5 0 68.3-20.1 85.1-49.7a97.76 97.76 0 0 0 149.6 25.4l19.4 22.2h3v-87.8h-80l24.3 27.5zM97.8 145c-26 0-47.1-21.1-47.1-47.1s21.1-47.1 47.1-47.1 47.2 21 47.2 47S123.8 145 97.8 145"
        />
      </svg>
      <span class="govuk-footer__licence-description">
        All content is available under the
        <a
          class="govuk-footer__link"
          href="https://www.nationalarchives.gov.uk/doc/open-government-licence/version/3/"
          rel="license"
        >Open Government Licence v3.0</a>, except where otherwise stated
      </span>
    </div>
    <div class="govuk-footer__meta-item">
      <a
        class="govuk-footer__link govuk-footer__copyright-logo"
        href="https://www.nationalarchives.gov.uk/information-management/re-using-public-sector-information/uk-government-licensing-framework/crown-copyright/"
      >¬© Crown copyright</a>
    </div>
  </div>
</footer>

        </div>
      </div>
    </div>

    
    <script src="/javascripts/application.js"></script>
  </body>
</html>
